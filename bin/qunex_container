#!/usr/bin/env python
# encoding: utf-8
#
# SPDX-FileCopyrightText: 2021 QuNex development team <https://qunex.yale.edu/>
#
# SPDX-License-Identifier: GPL-3.0-or-later

from __future__ import print_function, division
import subprocess
import os
import tempfile
import sys
import re
import math

from datetime import datetime


class CommandError(Exception):
    """There was an error in calling the command."""
    
    def __init__(self, function=None, error=None, *hints):
        if function is None:
            function = "unknown function"
        if error is None:
            error = "unspecified"
        msg = "Error '%s' occured in %s" % (error, function)
        super(CommandError, self).__init__(msg)
        self.function = function
        self.error    = error
        self.hints    = hints
        self.report   = (error,) + hints


class CommandFailed(Exception):
    """A command has failed to carry out fully."""

    def __init__(self, function=None, error=None, *hints):
        if function is None:
            function = "unknown function"
        if error is None:
            error = "unspecified"
        msg = "Error '%s' occured in %s" % (error, function)
        super(CommandFailed, self).__init__(msg)
        self.function = function
        self.error    = error
        self.hints    = hints
        self.report   = (error,) + hints


def schedule(command=None, script=None, scheduler=None, scheduler_params=None, replace=None, workdir=None, environment=None, output=None, parsessions=1, parelements=1, batchlogsfolder=None, slurm_array=False):
    '''
    qunex_command scheduler 

    USE
    ===

    Schedules the provided command to be run by the specified scheduler (PBS, 
    LSF, SLURM are currently supported).

    INPUTS
    ======

    Required parameter
    ------------------

    --scheduler  A string specifying the scheduler to be used and the additional
                 settings for it.

    `scheduler` string should be a comma separated list of parameters. The first
    parameter has to be the scheduler name (PBS, LSF, SLURM), the rest of the
    parameters are key-value pairs that are to be passed as settings to the
    scheduler. Additional parameters common to all the schedulers can be
    specified:

    - jobname  ... the name of the job to run
    - comname  ... the name of the command the job runs
    - jobnum   ... the number of the job being run

    Example settings strings:

    "SLURM,jobname=bet1,time=03-24:00:00,cpus-per-task=2,mem-per-cpu=2500,partition=pi_anticevic"
    "LSF,jobname=DWIproc,jobnum=1,cores=20,mem=250000,walltime=650:00,queue=anticevic"

    Optional parameter
    ------------------

    --output        A string specifying whether to return or redirect the
                    standard output and error. See "REDIRECTING OUTPUT" for
                    details

    If the optional parameter is not specified, it will not be used.


    REDIRECTING OUTPUT
    ==================

    If no output is specified, the job's standard output and error (stdout,
    stderr) are left as is and processed by the scheduler, and the result of
    submitting the job is printed to standard output. Output string can specify
    four different directives provided by "<key>:<value>" strings separated by
    pipe:

    stdout 
        specifies a path to a log file that should store standard output of the 
        submitted job
    stderr 
        specified a path to a log file that should store error output of the 
        submitted job
    both   
        specifies a path to a log file that should store joint standard and 
        error outputs of the submitted job

    Examples:

    . "stdout:processing.log"
    . "stdout:processing.output.log|stderr:processing.error.log"

    Do not specify error and standard outputs both using --output parameter and
    scheduler specific options within settings string.

    SCHEDULER SPECIFICS
    ===================

    Each of the supported scheduler systems has a somewhat different way of
    specifying job parameters. Please see documentation for each of the
    supported schedulers to provide the correct settings. Below are the
    information for each of the schedulers on how to specify --settings.

    PBS settings
    ------------

    PBS uses various flags to specify parameters. Be careful that the settings
    string includes only comma separated 'key=value' pairs. Scheduler will then
    do its best to use the right flags. Specifically:

    Keys: mem, walltime, software, file, procs, pmem, feature, host,
    naccesspolicy, epilogue, prologue will be submitted using::

        "#PBS -l <key>=<value>"

    Keys: j, m, o, S, a, A, M, q, t, e, N, l will be submitted using::
    
        "#PBS -<key> <value>"

    Key: depend will be submitted using::

        "#PBS -W depend=<value>"

    Key: umask will be submitted using::

        "#PBS -W umask=<value>"

    Key: nodes is a special case. It will be submitted as::

        "#PBS -l <value>"

    LSF settings
    ------------

    For LSF the following key/value parameters are parsed as:

    - queue    ... "#BSUB -q <queue>"
    - mem      ... "#BSUB -R 'span[hosts=1] rusage[mem=<mem>]"
    - walltime ... "#BSUB -W <walltime>"
    - cores    ... "#BSUB -n <cores>"

    Keys: g, G, i, L, cwd, outdir, p, s, S, sla, sp, T, U, u, v, e, eo, o, oo, 
    jobName will be submitted using::

        "#BSUB -<key> <value>"

    SLURM settings
    --------------

    For SLURM any provided key/value pair will be passed in the form:
    "#SBATCH --<key>=<value>"

    Some of the possible parameters to set are:

    - partition        ... The partition (queue) to use
    - nodes            ... Total number of nodes to run on
    - cpus-per-task    ... Number of cores per task
    - time             ... Maximum wall time DD-HH:MM:SS
    - constraint       ... Specific node architecture
    - mem-per-cpu      ... Memory requested per CPU in MB
    - mail-user        ... Email address to send notifications to
    - mail-type        ... On what events to send emails

    '''

    # --- check inputs
    if command is None and script is None:
        raise CommandError("schedule", "Missing parameter", "Either command or script need to be specified to run scheduler!")

    if command is not None and script is not None:
        raise CommandError("schedule", "Parameter conflict", "Only command or script need to be provided to run scheduler!")

    if scheduler_params is None:
        raise CommandError("schedule", "Missing parameter", "Scheduler parameters need to be provided to run scheduler!")

    # --- parse settings
    try:
        jobname   = scheduler_params.pop('jobname', "schedule")
        comname   = scheduler_params.pop('comname', "")
        jobnum    = scheduler_params.pop('jobnum', "")
    except:
        raise CommandError("schedule", "Misspecified parameter", "Could not parse the settings string:", settings)

    # --- compile command to pass
    if command is None:
        if not os.path.exists(script):
            raise CommandFailed("schedule", "File not found", "The specified script does not exist! [%s]" % (script))
        command = open(script, "r")

    if workdir is not None:
        if not os.path.exists(workdir):
            raise CommandFailed("schedule", "Folder does not exist", "The specified working directory does not exist! [%s]" % (workdir))
        command = "cd %s\n" % (workdir) + command

    if environment is not None:
        if not os.path.exists(environment):
            raise CommandFailed("schedule", "File not found", "The specified environment script does not exist! [%s]" % (environment))
        command = open(environment, "r") + "\n" + command

    # --- do search replace
    if replace is not None:
        replace = [e.strip().split(":") for e in replace.split("|")]

        for key, value in replace:
            command.replace("{{%s}}" % (key), value)

    # --- parse output
    outputs = {'stdout': None, 'stderr': None, 'both': None, 'return': None}

    if output is not None:
        for k, v in [[f.strip() for f in e.split(":")] for e in output.split("|")]:
            if not os.path.exists(os.path.dirname(v)) and k != 'return':
                raise CommandFailed("schedule", "Folder does not exist", "The specified folder for the '%s' log file does not exist! [%s]" % (k, os.path.dirname(v)), "Please check your paths!")
            outputs[k] = v
    else:
        # log name
        timestamp = datetime.now().strftime("%Y-%m-%d_%H.%M.%S.%f")

        if not slurm_array:
            logname = "/qunex_container_" + timestamp + ".txt"
        else:
            logname = "/qunex_container_job%a_" + timestamp + ".txt"

        # put in batchfolder
        if batchlogsfolder is not None:
            outputs['stdout'] = batchlogsfolder + logname
            outputs['stderr'] = batchlogsfolder + logname
        else:
            homedir = os.path.expanduser("~")
            outputs['stdout'] = homedir + logname
            outputs['stderr'] = homedir + logname

    if outputs['both'] is not None:
        outputs['stderr'] = outputs['both']
        outputs['stdout'] = outputs['both']

    # --- build scheduler commands
    sCommand = ""

    if scheduler == "PBS":
        for k, v in scheduler_params.items():
            if k in ('mem', 'walltime', 'software', 'file', 'procs', 'pmem', 'feature', 'host', 'naccesspolicy', 'epilogue', 'prologue'):
                sCommand += "#PBS -l %s=%s\n" % (k, v)
            elif k in ('j', 'm', 'o', 'S', 'a', 'A', 'M', 'q', 't', 'e', 'l'):
                sCommand += "#PBS -%s %s\n" % (k, v)
            elif k == 'depend':
                sCommand += "#PBS -W depend=%s\n" % (v)
            elif k == 'umask':
                sCommand += "#PBS -W umask=%s\n" % (v)
            elif k == 'N' and jobname == 'schedule':
                jobname = v
            elif k == 'nodes':
                sCommand += "#PBS -l nodes=%s\n" % v

        # set default nodes
        if ("nodes" not in scheduler_params.keys()):
            sCommand += "#PBS -l nodes=1:ppn=%s\n" % (parsessions * parelements)

        # job name
        if (comname != ""):
            jobname = "%s-%s" % (jobname, comname)
        if (jobnum != ""):
            jobname = "%s(%s)" % (jobname, jobnum)
        sCommand += "#PBS -N %s\n" % jobname

        if outputs['stdout'] is not None:
            sCommand += "#PBS -o %s\n" % (outputs['stdout'])
        if outputs['stderr'] is not None:
            sCommand += "#PBS -e %s\n" % (outputs['stderr'])
        if outputs['both']:
            sCommand += "#PBS -j oe\n"
        com = 'qsub'

    elif scheduler == "LSF":
        sCommand += "#BSUB -o %s-%s_#%s_%%J\n" % (jobname, comname, jobnum)
        for k, v in [('queue', '#BSUB -q %s\n'), ('mem', "#BSUB -R 'span[hosts=1] rusage[mem=%s]'\n"), ('walltime', '#BSUB -W %s\n'), ('cores', '#BSUB -n %s\n')]:
            if k in scheduler_params:
                sCommand += v % (scheduler_params[k])
        for k, v in scheduler_params.items():
            if k in ('g', 'G', 'i', 'L', 'cwd', 'outdir', 'p', 's', 'S', 'sla', 'sp', 'T', 'U', 'u', 'v', 'e', 'eo', 'o', 'oo'):
                sCommand += "#BSUB -%s %s\n" % (k, v)
            elif k == 'jobName' and jobname == 'schedule':
                jobname = v

        # set default cores
        if ("cores" not in scheduler_params.keys()):
            sCommand += "#BSUB -n %s\n" % (parsessions * parelements)

        # jobname
        if (comname != ""):
            jobname = "%s-%s" % (jobname, comname)
        sCommand += "#BSUB -P %s\n" % jobname
        if (jobnum != ""):
            jobname = "%s(%s)" % (jobname, jobnum)
        sCommand += "#BSUB -J %s\n" % jobname

        if outputs['stdout'] is not None:
            sCommand += "#BSUB -o %s\n" % (outputs['stdout'])
        if outputs['stderr'] is not None:
            sCommand += "#BSUB -e %s\n" % (outputs['stderr'])
        com = 'bsub'

    elif scheduler == "SLURM":
        sCommand += "#!/bin/sh\n"
        for key, value in scheduler_params.items():
            if key in ('J', 'job-name') and jobname == 'schedule':
                jobname = v
            elif value == "QX_FLAG":
                sCommand += "#SBATCH --%s\n" % (key.replace('--', ''))
            else:
                sCommand += "#SBATCH --%s=%s\n" % (key.replace('--', ''), value)

        # set default cpus-per-task
        if ("cpus-per-task" not in scheduler_params.keys() and "c" not in scheduler_params.keys()):
            sCommand += "#SBATCH --cpus-per-task=%s\n" % (parsessions * parelements)

        # jobname
        if (comname != ""):
            jobname = "%s-%s" % (jobname, comname)
        if (jobnum != ""):
            jobname = "%s(%s)" % (jobname, jobnum)
        sCommand += "#SBATCH --job-name=%s\n" % jobname

        if outputs['stdout'] is not None:
            sCommand += "#SBATCH -o %s\n" % (outputs['stdout'])
        if outputs['stderr'] is not None:
            sCommand += "#SBATCH -e %s\n" % (outputs['stderr'])
        com = 'sbatch'

    # --- run scheduler
    print("\nSubmitting:\n------------------------------")
    print(sCommand)
    print(command + "\n")

    if outputs['return'] is None:
        serr = None
        sout = None
    elif outputs['return'] == 'both':
        serr = subprocess.STDOUT
        sout = subprocess.PIPE
    elif outputs['return'] == 'stderr':
        serr = subprocess.PIPE
        sout = None
    elif outputs['return'] == 'stdout':
        serr = None
        sout = subprocess.PIPE

    run = subprocess.Popen(com, shell=True, stdin=subprocess.PIPE, stdout=sout, stderr=serr, close_fds=True)
    run.stdin.write((sCommand + command).encode('utf-8'))
    run.stdin.close()

    # ---- returning results
    if outputs['return'] in ['both', 'stdout']:
        result = run.stdout.read()
        return result
    elif outputs['return'] in ['stderr']:
        result = run.stderr.read()
        return result


def getSessionIDsFromBatchFile(filename):
    '''
    getSessionIDsFromBatchFile(filename)

    An internal function for reading batch.txt files. It reads the file and
    returns a list of sessions with the information on images and the additional
    parameters specified in the header.

    '''

    if not os.path.exists(filename):
        print("\n\n=====================================================\nERROR: Batch file does not exist [%s]", file=filename)
        raise ValueError("ERROR: Batch file not found: %s" % (filename))

    s = open(filename, "r").read()
    s = s.replace("\r", "\n")
    s = s.replace("\n\n", "\n")
    s = re.sub("^#.*?\n", "", s)

    s = s.split("\n---")
    s = [e for e in s if len(e) > 10]

    sessionids = []

    for sub in s:
        sub = sub.split('\n')
        sub = [e.strip() for e in sub]
        sub = [e.split("#")[0].strip() for e in sub]
        sub = [e for e in sub if len(e) > 0]

        for line in sub:
            line = [e.strip() for e in line.split(":")]

            # id line
            if len(line) == 2 and line[0] == "id":
                sessionids.append(line[1])
                break

    return sessionids


def getSessionIDsFromList(filename):
    '''
    getSessionIDsFromList(filename)

    An internal function for reading list files. It reads the file and
    returns a list of session ids.

    '''

    if not os.path.exists(filename):
        print("\n\n=====================================================\nERROR: List file does not exist [%s]", file=filename)
        raise ValueError("ERROR: List file not found: %s" % (filename))

    sessionids  = []

    with open(filename) as f:
        for line in f:
            if line.strip()[:1] == "#":
                continue

            line = [e.strip() for e in line.split(":")]

            if len(line) == 2 and line[0] == "subject id":
                sessionids.append(line[1])

    return sessionids


def getSessionIDs(listString, sessionsfolder=None):
    '''
    getSessionIDs(listString)

    An internal function for getting a list of subject ids.

    The provided listString can be:

    - a comma, space or pipe separated list of subject id codes,
    - a path to a batch file (identified by .txt extension),
    - a path to a *.list file (identified by .list extension).

    '''

    listString = listString.strip().replace(" ", "")

    if re.match(".*\.list$", listString):
        sessionids = getSessionIDsFromList(listString)

    elif os.path.isfile(listString):
        sessionids = getSessionIDsFromBatchFile(listString)

    elif re.match(".*\.txt$", listString) or '/' in listString:
        raise ValueError("ERROR: The specified file is not found! [%s]!" % listString)

    else:
        sessionids = [e.strip() for e in re.split(' +|,|\|', listString)]

    return sessionids


def get_batchlogs_folder(sessionsfolder):
    """
    ``deduceFolders(args)``

    Tries to deduce the location of study specific folders based on the provided
    arguments. For internal use only.
    """

    # extract folder
    f = os.path.abspath(sessionsfolder)

    # basefolder
    basefolder = None

    # try to find the root
    while os.path.dirname(f) and os.path.dirname(f) != '/':
        f = os.path.dirname(f)
        if os.path.exists(os.path.join(f, '.qunexstudy')):
            basefolder = f
            break
        elif os.path.exists(os.path.join(f, '.mnapstudy')):
            basefolder = f
            break
    
    # log folder
    batchlogsfolder = None

    if basefolder is not None:
        batchlogsfolder = os.path.join(basefolder, 'processing', 'logs', 'batchlogs')

    return batchlogsfolder


def main(args=None):
    """
    qunex_container is a self-standing command that can run QuNex commands 
    against a Singularity or a Docker QuNex container. To run an QuNex command 
    against a container the basic call is::

        qunex_container <qunex command> [parameters] \
        --container="<a path to the Singularity image or a Docker container name>" [additional options]
    
    `qunex command` is any command supported by QuNex. `parameters` are any
    parameters that should be passed to the qunex command. This part is the same
    as running::

        qunex <qunex command> [parameters]

    from within a container or on a self-standing QuNex installation. For list 
    of commands and their parameters consult QuNex online or in-line 
    documentation.

    Additionally qunex_container accepts the following parameters:

    INPUTS
    ======

    --container     specifies either the path to the Singularity container image 
                    or the full specification of the Docker container to be used
                    (e.g. qunex/qunex_suite:0_45_07). This parameter can be 
                    omitted if the value is specified in the `QUNEXCONIMAGE` 
                    environmental variable.
    --bash_pre      If any additional commands have to be run in bash before the
                    execution of qunex_container command itself. Use a semicolon
                    separated list to chain multiple commands. ['']
    --bash_post     Used if any additional commands have to be run inside the
                    QuNex container before executing the desired QuNex command.
                    Use a semicolon separated list to chain multiple commands. 
                    ['']
    --bind          Used for binding external folder for execution via a 
                    singularity container, this is analog to the singularity's 
                    -B flag. ['']
    --nocleanenv    By default QuNex will use the --cleanevn flag of Singularity
                    so your local environment setup will not be propagated into
                    the container. If you want to disable this functionality use
                    this flag. The flag is not set by default.
    --nv            Required when using CUDA (GPU) inside singularity. If
                    provided then singularity exec --nv option will be used.
    --script        If a script is to be run against the Singularity container
                    rather than a single command, the path to the script to be
                    run is specified here. ['']
    --envars        If environment variables other than the default set by the
                    container are to be used, they can be specified in a pipe
                    separated string formatted as:
                    "<variable>=><value>|<variable>=><value>"
                    Note that only the variables recognized by the QuNex suite
                    will be appropriately parsed and used in the container.
    --dockeropt     A string that lists the additional options to be used when
                    running the Docker container. If the parameter is ommited, 
                    the content of `QUNEXDOCKEROPT` environment variable will
                    be used. If neither is specified, the container will mount
                    the current as `data` by specifying the following options::

                        '-v "$(pwd)":/data'
                    
                    The parameters are to be specified in a string exactly as 
                    they would be on a command line, e.g. to run in detached
                    mode and mount a specific folder use::

                        "-d -v /host/directory:/container/directory"

    --scheduler     A string that specifies the details to use to submit the 
                    container job to a scheduling system. 
    --output        A string specifying where to redirect the standard output 
                    and error when using the scheduler. See "Redirecting 
                    output" for details!
    --parjobs       Specify the maximum amount of jobs that will be created
                    and run in parallel. By default this equals the number
                    of sessions your provided.
    --parsessions   Specify the amount of sessions that will be run in parallel
                    inside each created job. [1]
    --parelements   Specify the amount of elements that will be run in parallel
                    inside each session (for example BOLDs in hcp_fmri_volume).
                    [1]
    --parinfo       If this flag is set then qunex_container will not execute
                    the command, it will only printout the parallelism
                    information, e.g. how many jobs will be spawned, how many
                    sessions will be run in parallel, etc.

    RESULTS
    =======

    `qunex_container` will compile a temporary file with the relevant commands to 
    submit to the container. The file will be created in the users home folder
    and will be deleted as the last action completed by the container. In case 
    of a Docker container, to give access to the compiled script, the user's 
    home folder will be mounted as `/root` in the container, which is the home
    folder within the container.

    If a script parameter is specified, in case of a Singularity container, the 
    script will be executed using the `bash <script>` command. In case of a 
    Docker container, the content of the script will be appended to the 
    temporary script generated by the `qunex_container`. Do note that in the 
    case of the Singularity container the script can reference paths on the 
    host computer, whereas in the case of the Docker container, the script
    has to reference the paths and mounts as they are visible within the
    Docker container. 


    Scheduling jobs
    ---------------

    Container commands can be submitted to a scheduling system by specifying 
    the `--scheduler` parameter with a settings string. The settings string 
    should be a comma separated list of parameters. The first parameter has to 
    be the scheduler name (PBS, LSF, SLURM), the rest of the parameters are 
    key-value pairs that are to be passed as settings to the scheduler. 
    Additional parameters common to all the schedulers can be specified:

    - jobname ... the name of the job to run
    - comname ... the name of the command the job runs
    - jobnum  ... the number of the job being run

    Example settings strings::

        "SLURM,jobname=hcp_freesurfer,time=03-24:00:00,cpus-per-task=2,mem-per-cpu=2500,partition=pi_anticevic"
        "LSF,jobname=DWIproc,jobnum=1,cores=20,mem=250000,walltime=650:00,queue=pi_anticevic"


    Scheduling multiple jobs in parallel
    ------------------------------------
    
    If the parameters provided include --parjobs, --parsessions, --scheduler
    and --sessions, then qunex_container will spread the execution of the
    command by scheduling multiple jobs to run on separate nodes. Specifically,
    if --parjobs is not provided then QuNex will schedule a job for each of the
    sessions. If --parjobs is provided then QuNex will schedule at most the
    requested amount of jobs, inside each job QuNex will run at most
    --parsessions in parallel.  E.g. if 10 sessions are specified, parjobs
    is set to 3 and parsessions is set to 4, QuNex will schedule 3 jobs. The first
    job will run 4 sessions in parallel and the other 2 jobs will run 3 sessions
    in parallel.


    Passing --sessions parameter values cleanly
    -------------------------------------------

    In the case that --sessions parameter needs to be passed to a command, but
    not used to split up processing into multiple container calls (e.g. in 
    import_dicom or import_bids commands), specify the sessions to pass to the
    call using the --csessions parameter. The value of that parameter will be
    passed on as --sessions parameter to the command.


    Redirecting output
    ------------------

    By default, QuNex will try to put scheduler logs into the
    <study>/processing/logs/batchlogs folder. If not possible QuNex will put them
    in your home folder. You can also put them in a custom location by specifying
    the `output` parameter. The parameter supports three different directives
    provided by "<key>:<value>" pairs in a pipe separated string:

    stdout
        specifies a path to a log file that should store standard output of the 
        submitted job
    stderr
        specified a path to a log file that should store error output of the 
        submitted job
    both
        specifies a path to a log file that should store joint standard and 
        error outputs of the submitted job

    Examples:

    - "stdout:processing.log"
    - "stdout:processing.output.log|stderr:processing.error.log"
    - "both:processing.log"

    Do not specify error and standard outputs both using --output parameter and
    scheduler specific options within settings string. It is best to provide 
    full absolute paths to the desired log.

    
    EXAMPLE USE
    ===========

    ::

        qunex_container hcp_freesurfer \\
        --sessionsfolder=/data/study/sessions \\
        --sessions=/data/study/processing/batch.txt \\
        --parsessions=4 \\
        --container=/singularity/qunex_suite-0_38_10.simg \\
        --scheduler="SLURM,time=2-00:00:00,cpus-per-task=2,mem-per-cpu=15000,partition=pi_anticevic"

    """

    if args is None:
        args = sys.argv[1:]

    if not args:
        print(main.__doc__)
        exit()

    env_status          = False
    scheduler           = None
    conimage            = None
    command             = ""
    bash_pre            = None
    bash_post           = None
    bind                = None
    nocleanenv          = None
    nv                  = None
    script              = None
    parjobs             = None
    parsessions         = 1
    parelements         = 1
    sessions            = None
    sessionsfolder      = None
    sessionids          = None
    envars              = None
    dockeropt           = None
    output              = None
    csessions           = None
    parinfo             = None

    for arg in args:
        if "env_status" in arg or "envstatus" in arg:
            env_status = True
        if "scheduler=" in arg:
            k, scheduler = arg.split("=", 1)
        elif "container=" in arg:
            k, conimage = arg.split("=", 1)
        elif "envars=" in arg:
            k, envars = arg.split("=", 1)
        elif "dockeropt=" in arg:
            k, dockeropt = arg.split("=", 1)
        elif "output=" in arg:
            k, output = arg.split("=", 1)
        elif "bash_pre=" in arg:
            k, bash_pre = arg.split("=", 1)
        elif "bash_post=" in arg:
            k, bash_post = arg.split("=", 1)
        elif "bind=" in arg:
            k, bind = arg.split("=", 1)
        elif arg == "--nocleanenv":
            nocleanenv = True
        elif arg == "--nv":
            nv = True
        elif "script=" in arg:
            k, script = arg.split("=", 1)
        elif "parjobs=" in arg:
            k, parjobs = arg.split("=", 1)
            parjobs = int(parjobs)
        elif "parsessions=" in arg:
            k, parsessions = arg.split("=", 1)
            command += '%s="%s" ' % (k, parsessions)
            parsessions = int(parsessions)
        elif "parelements=" in arg:
            k, parelements = arg.split("=", 1)
            command += '%s="%s" ' % (k, parelements)
            parelements = int(parelements)
        elif "sessionsfolder=" in arg:
            k, sessionsfolder = arg.split("=", 1)
            command += '%s="%s" ' % (k, sessionsfolder)
        elif "sessions=" in arg:
            k, sessions = arg.split("=", 1)
        elif "csessions=" in arg:
            k, csessions = arg.split("=", 1)
            command += '--sessions="%s" ' % (csessions)
        elif "sessionids=" in arg:
            k, sessionids = arg.split("=", 1)
        elif "=" in arg:
            k, v = arg.split('=', 1)
            command += '%s="%s" ' % (k, v)
        elif arg.replace("-", "") == "parinfo":
            parinfo = True
        else:
            command += '%s ' % (arg)

    # batchlogs folder
    batchlogsfolder = None
    if sessionsfolder is not None:
        batchlogsfolder = get_batchlogs_folder(sessionsfolder)

    if conimage is None:
        if "QUNEXCONIMAGE" in os.environ:
            conimage = os.environ['QUNEXCONIMAGE']
        else:
            print("ERROR: No Singularity image or Docker container name specified either in the command line or as a QUNEXCONIMAGE environment variable!")
            exit(1)

    # docker or Singularity
    singularity = conimage.endswith(".simg") or conimage.endswith(".sif")

    # just report env status and quit
    if env_status:
        # singularity
        if singularity:
            env_command = "singularity exec %s bash /opt/qunex/env/qunex_container_env_status.sh" % conimage

        # docker
        else:
            env_command = "docker run %s bash -c \"/opt/qunex/env/qunex_container_env_status.sh\"" % conimage

        # run
        subprocess.Popen(env_command, shell=True)
        exit(0)

    if csessions is not None and sessions is not None:
        print("ERROR: Please specify either sessions or csessions, but not both!")
        exit(1)

    if command.startswith('?scheduler'):
        print(schedule.__doc__)
        exit()

    # -- check for environment variables
    if envars:
        envars = [e for e in envars.split('|')]
        envars = [e.split('=>') for e in envars if '=>' in e]
    else:
        envars = []

    # -- check for docker options
    if dockeropt is None:
        if "QUNEXDOCKEROPT" in os.environ:
            dockeropt = os.environ['QUNEXDOCKEROPT']
        else:
            dockeropt = "-v \"$(pwd)\":/data"

    homedir = os.path.expanduser("~")
    dockeropt += " -v %s:%s" % (homedir, homedir)

    # number of sessions
    n_sessions = None

    # get sessionsids init
    getsessionids = None

    # split sessions via sessionids or split existing sessionids
    if sessions is not None:
        if sessionids is None:
            getsessionids = getSessionIDs(sessions, sessionsfolder=sessionsfolder)
        else:
            temp_sessionids = getSessionIDs(sessions, sessionsfolder=sessionsfolder)
            sessionidsSplit = re.split(' +|,|\|', sessionids)
            getsessionids = [e for e in temp_sessionids if e in sessionidsSplit]

        n_sessions = len(getsessionids)

    # array for storing session ids
    sessionids_array = []

    # do not run in parallel multi_session/longitudinal commands
    multi_session_command = False
    multi_commands = ["longitudinal_freesurfer", "longitudinalFS", "hcp_temporal_ica", "hcp_make_average_dataset"]
    if any(c in command for c in multi_commands):
        multi_session_command = True

    scheduler_params_list = [e.strip() for e in scheduler.split(",")]
    scheduler = scheduler_params_list.pop(0)

    # check scheduler
    if scheduler not in ['PBS', 'LSF', 'SLURM']:
        raise CommandError("schedule", "Misspecified parameter", "First value in the settings string has to specify one of PBS, LSF, SLURM!", "The settings string submitted was:", scheduler)

    # are we using SLURM array, not by default
    slurm_array = False

    scheduler_params = {}

    for s in scheduler_params_list:
        # parameters with values
        if "=" in s:
            sSplit = s.split("=", 1)

            # SLURM job array?
            if scheduler == "SLURM" and sSplit[0].strip() == "array":
                slurm_array = True
           
            scheduler_params[sSplit[0].strip()] = sSplit[1].strip()
        # flags
        else:
            # SLURM job array?
            if scheduler == "SLURM" and s.strip() == "array":
                n_jobs = 1
                if n_sessions is not None:
                    n_jobs = n_sessions - 1
                slurm_array = True
                if parjobs is None:
                    scheduler_params["array"] = "0-%s" % (n_jobs)
                else:
                    scheduler_params["array"] = "0-%s%%%s" % (n_jobs, parjobs)
            else:
                scheduler_params[s.strip()] = "QX_FLAG"

    # if job array we have a single job
    if slurm_array:
        parjobs = 1

    # if scheduler is not None or we have a multi_session_command then setup parallelism
    if scheduler is not None and sessions is not None and not multi_session_command:
        # if parjobs is None each session is its own job
        if parjobs is None:
            parjobs = 0

            # split to chunks
            for i in range(0, n_sessions, parsessions):
                sessionids_array.append(','.join(getsessionids[i:i + parsessions]))

            # calculate the number of parallel jobs
            parjobs = len(sessionids_array)

        # else split jobs into chunks
        else:
            # how big are chunks of sessions
            chunks = int(math.ceil(n_sessions / float(parsessions)))

            # if chunks is lower then parjobs tweak parjobs
            if chunks < parjobs:
                parjobs = chunks

            # init queues
            sessionids_arrays = [[] for _ in range(parjobs)]

            # divide sessions among jobs
            for idx, sessionid in enumerate(getsessionids):
                job_id = idx % parjobs
                sessionids_arrays[job_id].append(sessionid)
            
            for s in sessionids_arrays:
                sessionids_array.append(",".join(s))

    else:
        # do not run in parallel
        parjobs = 1

        # add session ids
        if getsessionids is not None:
            sessionids_array.append(",".join(getsessionids))

    # print out details
    if n_sessions is not None:
        print("\n--> QuNex will run the command over %s sessions. It will utilize:\n" % n_sessions)
    else:
        print("\n--> QuNex will utilize:\n")
    print("    Scheduled jobs: %s " % parjobs)

    if n_sessions is not None:
        print("    Maximum sessions run in parallel for a job: %s." % parsessions)
        print("    Maximum elements run in parallel for a session: %s." % parelements)
        print("    Up to %s processes will be utilized for a job.\n" % (parelements * parsessions))

        if slurm_array:
            print("    Using SLURM job array over sessions: %s" % sessionids_array[0])
        else:
            for i in range(0, parjobs):
                print("    Job #%s will run sessions: %s" % ((i + 1), sessionids_array[i]))

    # schedule
    if parinfo is None:
        for i in range(0, parjobs):
            scheduleCommand = command

            # add sessionids to command?
            if i < len(sessionids_array):
                # if sessions is a batch file
                if os.path.isfile(sessions):
                    scheduleCommand += '--sessions="%s" ' % (sessions)
                    scheduleCommand += '--sessionids="%s" ' % (sessionids_array[i])
                else:
                    scheduleCommand += '--sessions="%s" ' % (sessionids_array[i])

                    if (sessionids is not None):
                        scheduleCommand += '--sessionids="%s" ' % (sessionids_array[i])

            elif sessions is not None:
                scheduleCommand += '--sessions="%s" ' % (sessions)

                if (sessionids is not None):
                    scheduleCommand += '--sessionids="%s" ' % (sessionids_array[i])

            # setup script
            fid, scriptPath = tempfile.mkstemp(dir=homedir)
            scriptName = os.path.basename(scriptPath)
            f = os.fdopen(fid, 'w')

            for k, v in envars:
                print("export con_%s=\"%s\"" % (k, v), file=f)
            print("source /opt/qunex/env/qunex_environment.sh", file=f)

            if bash_post:
                print(bash_post, file=f)

            if script:
                if singularity:
                    print("bash " + script, file=f)
                else:
                    with open(script, 'r') as sfile:
                        for line in sfile:
                            print(line, file=f)
            elif 'runTurnkey' in scheduleCommand:
                scheduleCommand = scheduleCommand.replace('runTurnkey', '')
                print("bash /opt/qunex/bash/qx_utilities/run_turnkey.sh" + scheduleCommand, file=f)
                
            else:
                print("bash /opt/qunex/bin/qunex.sh " + scheduleCommand, file=f)

            containerCommand = ""
            if bash_pre:
                containerCommand += bash_pre + ";"

            if singularity:
                print("rm " + scriptPath, file=f)
                f.close()

                containerCommand += "singularity exec "

                # no clean env
                if nocleanenv is None:
                    containerCommand += "--cleanenv "

                # nv
                if nv:
                    containerCommand += " --nv "

                # bind
                if bind:
                    containerCommand += "-B %s " % bind

                containerCommand +=  "%s bash %s" % (conimage, scriptPath)
            else:
                print("rm " + os.path.join(homedir, scriptName), file=f)
                f.close()

                containerCommand = "docker run %s %s bash %s/%s" % (dockeropt, conimage, homedir, scriptName)

            if scheduler:
                schedule(command=containerCommand, scheduler=scheduler, scheduler_params=scheduler_params.copy(), output=output, parsessions=parsessions, parelements=parelements, batchlogsfolder=batchlogsfolder, slurm_array=slurm_array)
            else:
                subprocess.Popen(containerCommand, shell=True)

if __name__ == "__main__":
    main()
