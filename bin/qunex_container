#!/usr/bin/env python
# encoding: utf-8
#
# SPDX-FileCopyrightText: 2021 QuNex development team <https://qunex.yale.edu/>
#
# SPDX-License-Identifier: GPL-3.0-or-later
#
# Version 0.100.0 [QX IO]

from __future__ import print_function, division
import subprocess
import os
import sys
import re
import math

from datetime import datetime


class CommandError(Exception):
    """There was an error in calling the command."""

    def __init__(self, function=None, error=None, *hints):
        if function is None:
            function = "unknown function"
        if error is None:
            error = "unspecified"
        msg = f"Error '{error}' occured in {function}"
        super(CommandError, self).__init__(msg)
        self.function = function
        self.error = error
        self.hints = hints
        self.report = (error,) + hints


class CommandFailed(Exception):
    """A command has failed to carry out fully."""

    def __init__(self, function=None, error=None, *hints):
        if function is None:
            function = "unknown function"
        if error is None:
            error = "unspecified"
        msg = f"Error '{error}' occured in {function}"
        super(CommandFailed, self).__init__(msg)
        self.function = function
        self.error = error
        self.hints = hints
        self.report = (error,) + hints


def schedule(
    command=None,
    script=None,
    scheduler_name=None,
    scheduler_params=None,
    replace=None,
    workdir=None,
    environment=None,
    output=None,
    parsessions=1,
    parelements=1,
    batchlogsfolder=None,
    slurm_array=False,
):
    """
    qunex_command scheduler

    USE
    ===

    Schedules the provided command to be run by the specified scheduler (PBS and
    SLURM are currently supported).

    INPUTS
    ======

    Optional parameter
    ------------------

    --output        A string specifying whether to return or redirect the
                    standard output and error. See "REDIRECTING OUTPUT" for
                    details

    If the optional parameter is not specified, it will not be used.


    REDIRECTING OUTPUT
    ==================

    If no output is specified, the job's standard output and error (stdout,
    stderr) are left as is and processed by the scheduler, and the result of
    submitting the job is printed to standard output. Output string can specify
    four different directives provided by "<key>:<value>" strings separated by
    pipe:

    stdout
        specifies a path to a log file that should store standard output of the
        submitted job
    stderr
        specified a path to a log file that should store error output of the
        submitted job
    both
        specifies a path to a log file that should store joint standard and
        error outputs of the submitted job

    Examples:

    . "stdout:processing.log"
    . "stdout:processing.output.log|stderr:processing.error.log"

    Do not specify error and standard outputs both using --output parameter and
    scheduler specific options within settings string.

    SCHEDULER SPECIFICS
    ===================

    Each of the supported scheduler systems has a somewhat different way of
    specifying job parameters. Please see documentation for each of the
    supported schedulers to provide the correct settings. Below are the
    information for each of the schedulers on how to specify --settings.

    PBS settings
    ------------

    PBS uses various flags to specify parameters. Be careful that the settings
    string includes only comma separated 'key=value' pairs. Scheduler will then
    do its best to use the right flags. Specifically:

    Keys: mem, walltime, software, file, procs, pmem, feature, host,
    naccesspolicy, epilogue, prologue will be submitted using::

        "#PBS -l <key>=<value>"

    Keys: j, m, o, S, a, A, M, q, t, e, N, l will be submitted using::

        "#PBS -<key> <value>"

    Key: depend will be submitted using::

        "#PBS -W depend=<value>"

    Key: umask will be submitted using::

        "#PBS -W umask=<value>"

    Key: nodes is a special case. It will be submitted as::

        "#PBS -l <value>"

    SLURM settings
    --------------

    For SLURM any provided key/value pair will be passed in the form:
    "#SBATCH --<key>=<value>"

    Some of the possible parameters to set are:

    - partition        ... The partition (queue) to use
    - nodes            ... Total number of nodes to run on
    - cpus-per-task    ... Number of cores per task
    - time             ... Maximum wall time DD-HH:MM:SS
    - constraint       ... Specific node architecture
    - mem-per-cpu      ... Memory requested per CPU in MB
    - mail-user        ... Email address to send notifications to
    - mail-type        ... On what events to send emails
    """

    # check inputs
    if command is None and script is None:
        raise CommandError(
            "schedule",
            "Missing parameter",
            "Either command or script need to be specified to run scheduler!",
        )

    if command is not None and script is not None:
        raise CommandError(
            "schedule",
            "Parameter conflict",
            "Only command or script need to be provided to run scheduler!",
        )

    if scheduler_params is None:
        raise CommandError(
            "schedule",
            "Missing parameter",
            "Scheduler parameters need to be provided to run scheduler!",
        )

    # parse settings
    try:
        jobname = scheduler_params.pop("jobname", "qunex_job")
    except:
        raise CommandError(
            "schedule",
            "Misspecified parameter",
            "Could not parse the settings string:",
            scheduler_params,
        )

    # compile command to pass
    if command is None:
        if not os.path.exists(script):
            raise CommandFailed(
                "schedule",
                "File not found",
                f"The specified script does not exist! [{script}]",
            )
        command = open(script, "r", encoding="UTF-8")

    # dirs
    if workdir is not None:
        if not os.path.exists(workdir):
            raise CommandFailed(
                "schedule",
                "Folder does not exist",
                f"The specified working directory does not exist! [{workdir}]",
            )
        command = f"cd {workdir}\n" + command

    if environment is not None:
        if not os.path.exists(environment):
            raise CommandFailed(
                "schedule",
                "File not found",
                f"The specified environment script does not exist! [{environment}]",
            )
        command = open(environment, "r", encoding="UTF-8") + "\n" + command

    # do search replace
    if replace is not None:
        replace = [e.strip().split(":") for e in replace.split("|")]

        for key, value in replace:
            command.replace("{{%s}}" % (key), value)

    # parse output
    outputs = {"stdout": None, "stderr": None, "both": None, "return": None}
    if output is not None:
        for k, v in [[f.strip() for f in e.split(":")] for e in output.split("|")]:
            if not os.path.exists(os.path.dirname(v)) and k != "return":
                raise CommandFailed(
                    "schedule",
                    "Folder does not exist",
                    f"The specified folder for the {k} log file does not exist [{os.path.dirname(v)}]!",
                    "Please check your paths!",
                )
            outputs[k] = v
    else:
        # log name
        timestamp = datetime.now().strftime("%Y-%m-%d_%H.%M.%S.%f")

        if not slurm_array:
            logname = f"/qunex_container_{timestamp}.txt"
        else:
            logname = f"/qunex_container_job%a_{timestamp}.txt"

        # put in batchfolder
        if batchlogsfolder is not None:
            outputs["stdout"] = batchlogsfolder + logname
            outputs["stderr"] = batchlogsfolder + logname
        else:
            homedir = os.path.expanduser("~")
            outputs["stdout"] = homedir + logname
            outputs["stderr"] = homedir + logname

    if outputs["both"] is not None:
        outputs["stderr"] = outputs["both"]
        outputs["stdout"] = outputs["both"]

    # build scheduler commands
    s_command = ""

    if scheduler_name == "PBS":
        for k, v in scheduler_params.items():
            if k in (
                "mem",
                "walltime",
                "software",
                "file",
                "procs",
                "pmem",
                "feature",
                "host",
                "naccesspolicy",
                "epilogue",
                "prologue",
                "select",
            ):
                s_command += f"#PBS -l {k}={v}\n"
            elif k in ("j", "m", "o", "S", "a", "A", "M", "q", "t", "e", "l"):
                s_command += f"#PBS -{k} {v}\n"
            elif k == "depend":
                s_command += f"#PBS -W depend={v}\n"
            elif k == "umask":
                s_command += f"#PBS -W umask={v}\n"
            elif k == "N" and jobname == "qunex_job":
                jobname = v
            elif k == "nodes":
                s_command += f"#PBS -l nodes={v}\n"

        # job name
        s_command += f"#PBS -N {jobname}\n"

        if outputs["stdout"] is not None:
            s_command += f"#PBS -o {outputs['stdout']}\n"
        if outputs["stderr"] is not None:
            s_command += f"#PBS -e {outputs['stderr']}\n"
        if outputs["both"]:
            s_command += "#PBS -j oe\n"
        com = "qsub"

    elif scheduler_name == "SLURM":
        s_command += "#!/bin/bash\n"
        for key, value in scheduler_params.items():
            if key in ("J", "job-name") and jobname == "qunex_job":
                jobname = value
            elif value == "QX_FLAG":
                s_command += f"#SBATCH --{key.replace('--', '')}\n"

            else:
                s_command += f"#SBATCH --{key.replace('--', '')}={value}\n"

        # set default cpus-per-task
        if (
            "cpus-per-task" not in scheduler_params.keys()
            and "c" not in scheduler_params.keys()
        ):
            s_command += f"#SBATCH --cpus-per-task={parsessions * parelements}\n"

        # jobname
        s_command += f"#SBATCH --job-name={jobname}\n"

        if outputs["stdout"] is not None:
            s_command += f"#SBATCH -o {outputs['stdout']}\n"
        if outputs["stderr"] is not None:
            s_command += f"#SBATCH -e {outputs['stderr']}\n"
        com = "sbatch"

    # run the scheduler
    print("\nSubmitting:\n------------------------------")
    print(s_command)
    print(command + "\n")

    if outputs["return"] is None:
        serr = None
        sout = None
    elif outputs["return"] == "both":
        serr = subprocess.STDOUT
        sout = subprocess.PIPE
    elif outputs["return"] == "stderr":
        serr = subprocess.PIPE
        sout = None
    elif outputs["return"] == "stdout":
        serr = None
        sout = subprocess.PIPE

    run = subprocess.Popen(
        com, shell=True, stdin=subprocess.PIPE, stdout=sout, stderr=serr, close_fds=True
    )
    run.stdin.write((s_command + command).encode("utf-8"))
    run.stdin.close()

    # returning results
    if outputs["return"] in ["both", "stdout"]:
        result = run.stdout.read()
        return result
    elif outputs["return"] in ["stderr"]:
        result = run.stderr.read()
        return result


def get_sessionids_from_batch(filename, batchfilter=None):
    """
    get_sessionids_from_batch(filename, batchfilter=None)

    An internal function for reading batch.txt files. It reads the file and
    returns a list of sessions with the information on images and the additional
    parameters specified in the header.

    It returns only the sessions that match the provided filter.
    """

    if not os.path.exists(filename):
        print(
            "\n\n=====================================================\nERROR: Batch file does not exist [{filename}]"
        )
        raise ValueError(f"ERROR: Batch file not found: {filename}")

    s = open(filename, "r", encoding="UTF-8").read()
    s = s.replace("\r", "\n")
    s = s.replace("\n\n", "\n")
    s = re.sub("^#.*?\n", "", s)

    s = s.split("\n---")
    s = [e for e in s if len(e) > 10]

    sessionids = []

    # build the filter dictionary
    filters_dict = {}

    # did we provide a filter
    if batchfilter is not None:
        # split filter items
        filters = batchfilter.split("|")

        # iterate through them and store them
        for f in filters:
            f_split = f.split(":")
            filters_dict[f_split[0]] = f_split[1]

    for sub in s:
        sub = sub.split("\n")
        sub = [e.strip() for e in sub]
        sub = [e.split("#")[0].strip() for e in sub]
        sub = [e for e in sub if len(e) > 0]

        # variable for storing the session id
        session = None
        passes_filter = False
        for line in sub:
            line = [e.strip() for e in line.split(":")]

            # filter
            if len(line) == 2:
                # is it the id/session line
                if line[0] == "id" or line[0] == "session":
                    session = line[1]
                    if passes_filter:
                        sessionids.append(session)
                        break

                # should I filter
                if filters_dict and line[0] in filters_dict:
                    active_filter = filters_dict[line[0]].split(",")
                    if line[1] in active_filter or re.match(
                        filters_dict[line[0]], line[1]
                    ):
                        passes_filter = True
                        if session:
                            sessionids.append(session)
                            break
                elif session and not filters_dict:
                    sessionids.append(session)
                    break

    return sessionids


def get_sessionids(batchfile, sessions, batchfilter=None):
    """
    get_sessionids(batchfile, sessions, batchfilter=None)

    An internal function for getting a list of session ids.

    The batchfile parameter points to the location of the batch file.

    The batchfilter parameters is used for selecting a subset of sessions
    from the batch file.

    Sessions can be:
    - a comma, space or pipe separated list of session id codes,
    - a path to a *.list file (identified by .list extension).
    """

    sessionids = None

    # session have a higher priority
    if sessions is not None:
        if re.match(r".*\.list$", sessions):
            if os.path.isfile(sessions):
                sessionids = get_sessionids_from_list(sessions)
            else:
                raise ValueError(
                    f"ERROR: The specified file is not found! [{batchfile}]!"
                )
        else:
            sessionids = [
                e.strip() for e in re.split(r" +|,|\|", sessions.replace(" ", ""))
            ]
    # batchfile
    elif batchfile is not None:
        if os.path.isfile(batchfile):
            sessionids = get_sessionids_from_batch(batchfile, batchfilter)
        else:
            raise ValueError(f"ERROR: The specified file is not found! [{batchfile}]!")

    return sessionids


def get_sessionids_from_list(filename):
    """
    get_sessionids_from_list(filename)

    An internal function for reading list files. It reads the file and
    returns a list of session ids.

    """

    if not os.path.exists(filename):
        print(
            f"\n\n=====================================================\nERROR: List file does not exist [{filename}]"
        )
        raise ValueError(f"ERROR: List file not found: {filename}")

    sessionids = []

    with open(filename, encoding="UTF-8") as f:
        for line in f:
            if line.strip()[:1] == "#":
                continue

            line = [e.strip() for e in line.split(":")]

            if len(line) == 2 and line[0] in ["session id", "subject_id"]:
                sessionids.append(line[1])

    return sessionids


def get_batchlogs_folder(sessionsfolder):
    """
    ``get_batchlogs_folder(args)``

    Tries to deduce the location of study specific folders based on the provided
    arguments. For internal use only.
    """

    # extract folder
    f = os.path.abspath(sessionsfolder)

    # basefolder
    basefolder = None

    # try to find the root
    while os.path.dirname(f) and os.path.dirname(f) != "/":
        f = os.path.dirname(f)
        if os.path.exists(os.path.join(f, ".qunexstudy")):
            basefolder = f
            break
        elif os.path.exists(os.path.join(f, ".mnapstudy")):
            basefolder = f
            break

    # log folder
    batchlogsfolder = None

    if basefolder is not None:
        batchlogsfolder = os.path.join(basefolder, "processing", "logs", "batchlogs")

    return batchlogsfolder


def main(args=None):
    """
    qunex_container is a self-standing command that can run QuNex commands
    against a Singularity/Apptainer or a Docker QuNex container. To run an QuNex
    command  against a container the basic call is::

        qunex_container <qunex command> [parameters] \
        --container="<a path to the Singularity/Apptainer image or a Docker container name>" [additional options]

    `qunex command` is any command supported by QuNex. `parameters` are any
    parameters that should be passed to the qunex command. This part is the same
    as running::

        qunex <qunex command> [parameters]

    from within a container or on a self-standing QuNex installation. For list
    of commands and their parameters consult QuNex online or in-line
    documentation.

    Additionally qunex_container accepts the following parameters:

    INPUTS
    ======

    --container     specifies either the path to the Singularity/Apptainer
                    container image  or the full specification of the Docker
                    container to be used (e.g. qunex/qunex_suite:0_45_07).
    --bash_pre      If any additional commands have to be run in bash before the
                    execution of qunex_container command itself. Use a semicolon
                    separated list to chain multiple commands. ['']
    --bash_post     Used if any additional commands have to be run inside the
                    QuNex container before executing the desired QuNex command.
                    Use a semicolon separated list to chain multiple commands.
                    ['']
    --bind          Used for binding external folders in order for the system in
                    the container to have access to relvant data. Maps to -B
                    parameter of Singularity/Apptainer and -v parmaeter of
                    Docker.
    --nocleanenv    By default QuNex will use the --cleanenv flag of
                    Singularity/Apptainer so your local environment setup will
                    not be propagated into the container. If you want to disable
                    this functionality use this flag. The flag is not set by
                    default.
    --cuda          Use in order to prepare the container for CUDA usage. This
                    flag is not set by default.
    --cuda_path     Can be used to bind a local CUDA version over the one in the
                    system.
    --nv            An old way of using using CUDA inside Singularity/Apptainer.
                    If provided then --nv option will be used when executing.
    --script        If a script is to be run against the Singularity/Apptainer
                    container rather than a single command, the path to the
                    script to be run is specified here. ['']
    --containeropt  A string that lists the additional options to be used when
                    running the container. The parameters are to be specified in
                    a string exactly as they would be on a command line, e.g.
                    to run Docker in detached mode and mount a specific folder
                    use::

                        "-d -v /host/directory:/container/directory"

    --scheduler     A string that specifies the details to use to submit the
                    container job to a scheduling system.
    --output        A string specifying where to redirect the standard output
                    and error when using the scheduler. See "Redirecting
                    output" for details!
    --parjobs       Specify the maximum amount of jobs that will be created
                    and run in parallel. By default this equals the number
                    of sessions your provided.
    --parsessions   Specify the amount of sessions that will be run in parallel
                    inside each created job. [1]
    --parelements   Specify the amount of elements that will be run in parallel
                    inside each session (for example BOLDs in hcp_fmri_volume).
                    [1]
    --parinfo       If this flag is set then qunex_container will not execute
                    the command, it will only printout the parallelism
                    information, e.g. how many jobs will be spawned, how many
                    sessions will be run in parallel, etc.

    RESULTS
    =======

    `qunex_container` will compile a temporary file with the relevant commands to
    submit to the container. The file will be created in the users home folder
    and will be deleted as the last action completed by the container. In case
    of a Docker container, to give access to the compiled script, the user's
    home folder will be mounted as `/root` in the container, which is the home
    folder within the container.

    If a script parameter is specified, in case of a Singularity/Apptainer
    container, the script will be executed using the `bash <script>` command.
    In case of a Docker container, the content of the script will be appended
    to the temporary script generated by the `qunex_container`. Do note that in
    the case of the Singularity/Apptainer container the script can reference
    paths on the host computer, whereas in the case of the Docker container,
    the script has to reference the paths and mounts as they are visible within
    the Docker container.

    Scheduling jobs
    ---------------

    Container commands can be submitted to a scheduling system by specifying
    the `--scheduler` parameter with a settings string. The settings string
    should be a comma separated list of parameters. The first parameter has to
    be the scheduler name (PBS, SLURM), the rest of the parameters are
    key-value pairs that are to be passed as settings to the scheduler.

    Example settings strings::

        "SLURM,jobname=hcp_freesurfer,time=03-24:00:00,cpus-per-task=2,mem-per-cpu=2500,partition=week"

    Scheduling multiple jobs in parallel
    ------------------------------------

    If the parameters provided include --parjobs, --parsessions, --scheduler
    and --sessions or --batchfile, then qunex_container will spread the execution
    of the command by scheduling multiple jobs to run on separate nodes. Specifically,
    if --parjobs is not provided then QuNex will schedule a job for each of the
    sessions. If --parjobs is provided then QuNex will schedule at most the
    requested amount of jobs, inside each job QuNex will run at most
    --parsessions in parallel.  E.g. if 10 sessions are specified, parjobs
    is set to 3 and parsessions is set to 4, QuNex will schedule 3 jobs. The first
    job will run 4 sessions in parallel and the other 2 jobs will run 3 sessions
    in parallel.

    Redirecting output
    ------------------

    By default, QuNex will try to put scheduler logs into the
    <study>/processing/logs/batchlogs folder. If not possible QuNex will put them
    in your home folder. You can also put them in a custom location by specifying
    the `output` parameter. The parameter supports three different directives
    provided by "<key>:<value>" pairs in a pipe separated string:

    stdout
        specifies a path to a log file that should store standard output of the
        submitted job
    stderr
        specified a path to a log file that should store error output of the
        submitted job
    both
        specifies a path to a log file that should store joint standard and
        error outputs of the submitted job

    Examples:

    - "stdout:processing.log"
    - "stdout:processing.output.log|stderr:processing.error.log"
    - "both:processing.log"

    Do not specify error and standard outputs both using --output parameter and
    scheduler specific options within settings string. It is best to provide
    full absolute paths to the desired log.

    EXAMPLE USE
    ===========

    ::

        qunex_container hcp_freesurfer \\
            --sessionsfolder=/data/study/sessions \\
            --batchfile=/data/study/processing/batch.txt \\
            --parsessions=4 \\
            --container=/apptainer/qunex_suite-0_38_10.sif \\
            --scheduler="SLURM,time=2-00:00:00,cpus-per-task=2,mem-per-cpu=15000,partition=week"
    """

    if args is None:
        args = sys.argv[1:]

    if not args:
        print(main.__doc__)
        exit()

    # deprecation warnings
    for arg in args:
        if "sessionids=" in arg:
            print(
                "WARNING: The sessionids parameter will be deprecated, use the sessions parameter to select sessions."
            )
        if "sessions=" in arg and ".txt" in arg:
            print(
                "WARNING: It seems like you are using the sessions parameters to pass the location of the batch file to QuNex. This functionality will be deprecated, use the batchfile parameter for specifying the location of the batchfile."
            )

    env_status = False
    scheduler = None
    container = None
    command = ""
    bash_pre = None
    bash_post = None
    bind = None
    nocleanenv = None
    cuda = None
    nv = None
    cuda_path = None
    script = None
    parjobs = None
    parsessions = None
    parelements = 1
    batchfile = None
    batchfilter = None
    sessions = None
    sessionsfolder = None
    sessionids = None
    containeropt = ""
    output = None
    parinfo = None
    overwrite = None

    for arg in args:
        # cleanup -- at start
        if arg.startswith("--"):
            arg = arg[2:]

            if arg.startswith("env_status") or arg.startswith("envstatus"):
                env_status = True
            if arg.startswith("scheduler"):
                k, scheduler = arg.split("=", 1)
            elif arg.startswith("container"):
                k, container = arg.split("=", 1)
            elif arg.startswith("containeropt"):
                k, containeropt = arg.split("=", 1)
            elif arg.startswith("output"):
                k, output = arg.split("=", 1)
            elif arg.startswith("bash_pre"):
                k, bash_pre = arg.split("=", 1)
            elif arg.startswith("bash_post"):
                k, bash_post = arg.split("=", 1)
            elif arg.startswith("bind"):
                k, bind = arg.split("=", 1)
            elif arg.startswith("cuda_path"):
                k, cuda_path = arg.split("=", 1)
            elif arg.startswith("script"):
                k, script = arg.split("=", 1)
            elif arg.startswith("parjobs"):
                k, parjobs = arg.split("=", 1)
                parjobs = int(parjobs)
            elif arg.startswith("parsessions"):
                k, parsessions = arg.split("=", 1)
                command += f'--{k}="{parsessions}" '
                parsessions = int(parsessions)
            elif arg.startswith("parelements"):
                k, parelements = arg.split("=", 1)
                command += f'--{k}="{parelements}" '
                parelements = int(parelements)
            elif arg.startswith("sessionsfolder"):
                k, sessionsfolder = arg.split("=", 1)
                command += f'--{k}="{sessionsfolder}" '
            elif arg.startswith("sessions"):
                k, sessions = arg.split("=", 1)
            elif arg.startswith("batchfile"):
                k, batchfile = arg.split("=", 1)
            elif arg.startswith("filter"):
                k, batchfilter = arg.split("=", 1)
            elif arg.startswith("sessionids"):
                k, sessionids = arg.split("=", 1)
            elif arg.startswith("overwrite"):
                k, overwrite = arg.split("=", 1)
                command += f"--{arg} "
            elif arg == "nocleanenv":
                nocleanenv = True
            elif arg == "cuda":
                cuda = True
            elif arg == "nv":
                nv = True
            elif arg == "parinfo":
                parinfo = True
            elif "=" in arg:
                k, v = arg.split("=", 1)
                command += f'--{k}="{v}" '
            else:
                command += f"--{arg} "

        else:
            command += f"{arg} "

    # parsessions
    if parsessions is None:
        parsessions = 1

    # workaround for commands that are not supported
    commands_blacklist = [
        "create_batch",
        "create_list",
        "create_conc",
        "gather_behavior",
        "pull_sequence_names",
        "create_stats_report",
        "fc_compute_roifc",
        "fc_compute_gbc",
        "fc_compute_seedmaps",
        "fc_extract_roi_timeseries",
        "general_extract_roi_values",
        "general_extract_roi_glm_values",
        "run_qa",
    ]
    qx_command = command.split(" ")[0]
    # ban parallel execution of these commands
    if (
        (overwrite == "yes" or overwrite is True)
        and parsessions > 1
        and qx_command in commands_blacklist
    ):
        print(
            "ERROR: Parallel execution of this command is not supported when overwrite is set to yes!"
        )
        exit(1)

    # batchlogs folder
    batchlogsfolder = None
    if sessionsfolder is not None:
        batchlogsfolder = get_batchlogs_folder(sessionsfolder)

    if container is None:
        print(
            "ERROR: No Singularity/Apptainer image or Docker container name specified through the --container parameter!"
        )
        exit(1)

    # Docker or Apptainer
    apptainer = container.endswith(".simg") or container.endswith(".sif")

    # just report env status and quit
    if env_status:
        # apptainer
        if apptainer:
            env_command = f"singularity exec {container} bash /opt/qunex/env/qunex_container_env_status.sh"

        # docker
        else:
            env_command = f'docker run {container} bash -c "/opt/qunex/env/qunex_container_env_status.sh"'

        # run
        subprocess.Popen(env_command, shell=True)
        exit(0)

    if command.startswith("?scheduler"):
        print(schedule.__doc__)
        exit()

    # if sessions is a batch file set as batchfile
    old_sessions_naming = False
    if sessions is not None and ".txt" in sessions:
        if batchfile is not None:
            print(
                "ERROR: It seems like you passed the batchfile both through the sessions and the batchfile parameters!"
            )
            exit(1)
        else:
            batchfile = sessions
            sessions = sessionids
            sessionids = None
            old_sessions_naming = True
    elif sessions is not None and sessionids is not None:
        print(
            "WARNING: It seems like you are passing a list of sessions both through the sessions parameter and through the sessionids parameter!"
        )

    # number of sessions
    n_sessions = None

    # get sessionsids
    g_sessionids = get_sessionids(batchfile, sessions, batchfilter)
    if g_sessionids:
        n_sessions = len(g_sessionids)

    # do not run in parallel multi_session/longitudinal commands
    multi_session_command = False
    multi_commands = [
        "hcp_long_freesurfer",
        "hcp_long_post_freesurfer" "hcp_temporal_ica",
        "hcp_make_average_dataset",
        "fsl_melodic",
    ]
    if any(c in command for c in multi_commands):
        multi_session_command = True

    # are we using SLURM array, not by default
    slurm_array = False

    # init scheduler params
    if scheduler is not None:
        scheduler_params_list = [e.strip() for e in scheduler.split(",")]
        scheduler_name = scheduler_params_list.pop(0)

        # check scheduler
        if scheduler_name not in ["PBS", "SLURM"]:
            raise CommandError(
                "schedule",
                "Misspecified parameter",
                "First value in the settings string has to specify one of PBS or SLURM!",
                "The settings string submitted was:",
                scheduler_name,
            )

        # parse scheduler parameters
        scheduler_params = {}
        for s in scheduler_params_list:
            # parameters with values
            if "=" in s:
                str_split = s.split("=", 1)

                # SLURM job array?
                if scheduler_name == "SLURM" and str_split[0].strip() == "array":
                    slurm_array = True

                scheduler_params[str_split[0].strip()] = str_split[1].strip()
            # flags
            else:
                # SLURM job array?
                if scheduler_name == "SLURM" and s.strip() == "array":
                    n_jobs = 1
                    if n_sessions is not None:
                        n_jobs = n_sessions - 1
                    slurm_array = True
                    if parjobs is None:
                        scheduler_params["array"] = f"0-{n_jobs}"
                    else:
                        scheduler_params["array"] = f"0-{n_jobs}%%{parjobs}"
                else:
                    scheduler_params[s.strip()] = "QX_FLAG"

        # if job array we have a single job
        if slurm_array:
            parjobs = 1

            # only allow HCP MPP commands with job array
            array_commands = [
                "hcp_pre_freesurfer",
                "hcp_freesurfer",
                "hcp_post_freesurfer",
                "hcp_fmri_volume",
                "hcp_fmri_surface",
                "run_recipe",
            ]
            if qx_command not in array_commands:
                print(
                    "ERROR: SLURM job arrays are supported only for HCP Minimal Preprocessing Pipelines!"
                )
                print(
                    "         ... hcp_pre_freesurfer, hcp_freesurfer, hcp_post_freesurfer, hcp_fmri_volume and hcp_fmri_surface."
                )
                exit(1)

    # array for storing session ids
    sessionids_array = []

    # if scheduler is not None and we do not have a multi_session_command then setup parallelism
    if (
        scheduler is not None
        and (sessions is not None or batchfile is not None)
        and not multi_session_command
    ):
        # if parjobs is None each session is its own job
        if parjobs is None:
            parjobs = 0

            # split to chunks
            for i in range(0, n_sessions, parsessions):
                sessionids_array.append(",".join(g_sessionids[i : i + parsessions]))

            # calculate the number of parallel jobs
            parjobs = len(sessionids_array)

        # else split jobs into chunks
        else:
            # how big are chunks of sessions
            chunks = int(math.ceil(n_sessions / float(parsessions)))

            # if chunks is lower then parjobs tweak parjobs
            if chunks < parjobs:
                parjobs = chunks

            # init queues
            sessionids_arrays = [[] for _ in range(parjobs)]

            # divide sessions among jobs
            for idx, sessionid in enumerate(g_sessionids):
                job_id = idx % parjobs
                sessionids_arrays[job_id].append(sessionid)

            for s in sessionids_arrays:
                sessionids_array.append(",".join(s))

    else:
        # do not run in parallel
        parjobs = 1

        # add session ids
        if g_sessionids is not None:
            sessionids_array.append(",".join(g_sessionids))

    # print out details
    if scheduler:
        print(f"    Qunex will schedule {parjobs} jobs")

    if n_sessions is not None:
        print(
            f"\n---> QuNex will run the command over {n_sessions} sessions. It will utilize:\n"
        )
        print(f"    Maximum sessions run in parallel for a job: {parsessions}.")
        print(f"    Maximum elements run in parallel for a session: {parelements}.")
        print(
            f"    Up to {parelements * parsessions} processes will be utilized for a job.\n"
        )

        if slurm_array:
            print(f"    Using SLURM job array over sessions: {sessionids_array[0]}")
        else:
            for i in range(0, parjobs):
                print(f"    Job #{i + 1} will run sessions: {sessionids_array[i]}")

    # execute
    homedir = os.path.expanduser("~")
    if parinfo is None:
        for i in range(0, parjobs):
            qx_command = command

            # add batchfile to command?
            if batchfile is not None:
                if not old_sessions_naming:
                    qx_command += f'--batchfile="{batchfile}" '
                else:
                    qx_command += f'--sessions="{batchfile}" '

            # add sessions to command?
            if i < len(sessionids_array):
                if not old_sessions_naming:
                    qx_command += f'--sessions="{sessionids_array[i]}" '
                    # run_turnkey requires both
                    if "run_turnkey" in qx_command:
                        qx_command += f'--sessionids="{sessionids_array[i]}" '
                else:
                    qx_command += f'--sessionids="{sessionids_array[i]}" '
                    # run_turnkey requires both
                    if "run_turnkey" in qx_command:
                        qx_command += f'--sessions="{sessionids_array[i]}" '

            # setup script
            timestamp = datetime.now().strftime("%Y-%m-%d_%H.%M.%S.%f")
            # prepare the schedule file
            if batchlogsfolder is not None:
                script_path = os.path.join(
                    batchlogsfolder, f"qunex_container_command_{timestamp}.sh"
                )
            else:
                script_path = os.path.join(
                    homedir, f"qunex_container_command_{timestamp}.sh"
                )

            f = open(script_path, "w", encoding="UTF-8")

            print("source /opt/qunex/env/qunex_environment.sh", file=f)

            if bash_post:
                print(bash_post, file=f)

            if script:
                if apptainer:
                    print("bash " + script, file=f)
                else:
                    with open(script, "r", encoding="UTF-8") as sfile:
                        for line in sfile:
                            print(line, file=f)
            else:
                print("bash /opt/qunex/bin/qunex.sh " + qx_command, file=f)

            f.close()

            # setup the container command
            container_command = ""
            if bash_pre:
                container_command += bash_pre + ";"

            if apptainer:
                container_command += "singularity exec "

                # bind home
                container_command += f"--bind {homedir}:{homedir} "

                # containeropt
                if containeropt:
                    container_command += containeropt + " "

                # no clean env
                if nocleanenv is None:
                    container_command += "--cleanenv "
                    if slurm_array:
                        # the params we need are SLURM_ARRAY_TASK_ID and SLURM_ARRAY_TASK_MAX
                        # we do not need SLURM_JOB_ID, SLURM_ARRAY_JOB_ID, SLURM_ARRAY_TASK_COUNT, SLURM_ARRAY_TASK_MAX for now
                        slurm_array_params = [
                            "SLURM_ARRAY_TASK_ID",
                            "SLURM_ARRAY_TASK_MAX",
                        ]
                        # pass variables into the Singularity/Apptainer container
                        container_command += "--env "
                        container_command += ",".join(
                            [f"{p}=${{p}}" for p in slurm_array_params]
                        )
                        # add trailing space
                        container_command += " "

                # cuda
                if cuda:
                    container_command += "--nvccli -u "

                # nv
                if nv:
                    container_command += "--nv "

                # bind
                if bind:
                    container_command += f"--bind {bind} "

                # bind cuda path if provided
                if cuda_path:
                    container_command += f"--bind {cuda_path}:/usr/local/cuda/ "

                container_command += f"{container.strip()} bash {script_path.strip()}"
            else:
                container_command += "docker run "

                # bind home
                container_command += f"-v {homedir}:{homedir} "

                # containeropt
                if containeropt:
                    container_command += containeropt + " "

                # cuda
                if cuda:
                    container_command += "--gpus all "

                # bind cuda path if provided
                if cuda_path:
                    container_command += f"-v {cuda_path}:/usr/local/cuda "

                # bind
                if bind:
                    bind_list = bind.split(",")
                    for b in bind_list:
                        container_command += f"-v {b} "

                container_command += f"{container.strip()} bash {script_path.strip()}"
            if scheduler:
                schedule(
                    command=container_command,
                    scheduler_name=scheduler_name,
                    scheduler_params=scheduler_params.copy(),
                    output=output,
                    parsessions=parsessions,
                    parelements=parelements,
                    batchlogsfolder=batchlogsfolder,
                    slurm_array=slurm_array,
                )
            else:
                subprocess.Popen(container_command, shell=True)


if __name__ == "__main__":
    main()
