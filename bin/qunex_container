#!/usr/bin/env python
# encoding: utf-8
#
# SPDX-FileCopyrightText: 2021 QuNex development team <https://qunex.yale.edu/>
#
# SPDX-License-Identifier: GPL-3.0-or-later

from __future__ import print_function, division
import subprocess
import os
import sys
import re
import math

from datetime import datetime


class CommandError(Exception):
    """There was an error in calling the command."""
    
    def __init__(self, function=None, error=None, *hints):
        if function is None:
            function = "unknown function"
        if error is None:
            error = "unspecified"
        msg = "Error '%s' occured in %s" % (error, function)
        super(CommandError, self).__init__(msg)
        self.function = function
        self.error    = error
        self.hints    = hints
        self.report   = (error,) + hints


class CommandFailed(Exception):
    """A command has failed to carry out fully."""

    def __init__(self, function=None, error=None, *hints):
        if function is None:
            function = "unknown function"
        if error is None:
            error = "unspecified"
        msg = "Error '%s' occured in %s" % (error, function)
        super(CommandFailed, self).__init__(msg)
        self.function = function
        self.error    = error
        self.hints    = hints
        self.report   = (error,) + hints


def schedule(command=None, script=None, scheduler_name=None, scheduler_params=None, replace=None, workdir=None, environment=None, output=None, parsessions=1, parelements=1, batchlogsfolder=None, slurm_array=False):
    '''
    qunex_command scheduler 

    USE
    ===

    Schedules the provided command to be run by the specified scheduler (PBS, 
    LSF, SLURM are currently supported).

    INPUTS
    ======

    Optional parameter
    ------------------

    --output        A string specifying whether to return or redirect the
                    standard output and error. See "REDIRECTING OUTPUT" for
                    details

    If the optional parameter is not specified, it will not be used.


    REDIRECTING OUTPUT
    ==================

    If no output is specified, the job's standard output and error (stdout,
    stderr) are left as is and processed by the scheduler, and the result of
    submitting the job is printed to standard output. Output string can specify
    four different directives provided by "<key>:<value>" strings separated by
    pipe:

    stdout 
        specifies a path to a log file that should store standard output of the 
        submitted job
    stderr 
        specified a path to a log file that should store error output of the 
        submitted job
    both   
        specifies a path to a log file that should store joint standard and 
        error outputs of the submitted job

    Examples:

    . "stdout:processing.log"
    . "stdout:processing.output.log|stderr:processing.error.log"

    Do not specify error and standard outputs both using --output parameter and
    scheduler specific options within settings string.

    SCHEDULER SPECIFICS
    ===================

    Each of the supported scheduler systems has a somewhat different way of
    specifying job parameters. Please see documentation for each of the
    supported schedulers to provide the correct settings. Below are the
    information for each of the schedulers on how to specify --settings.

    PBS settings
    ------------

    PBS uses various flags to specify parameters. Be careful that the settings
    string includes only comma separated 'key=value' pairs. Scheduler will then
    do its best to use the right flags. Specifically:

    Keys: mem, walltime, software, file, procs, pmem, feature, host,
    naccesspolicy, epilogue, prologue will be submitted using::

        "#PBS -l <key>=<value>"

    Keys: j, m, o, S, a, A, M, q, t, e, N, l will be submitted using::
    
        "#PBS -<key> <value>"

    Key: depend will be submitted using::

        "#PBS -W depend=<value>"

    Key: umask will be submitted using::

        "#PBS -W umask=<value>"

    Key: nodes is a special case. It will be submitted as::

        "#PBS -l <value>"

    LSF settings
    ------------

    For LSF the following key/value parameters are parsed as:

    - queue    ... "#BSUB -q <queue>"
    - mem      ... "#BSUB -R 'span[hosts=1] rusage[mem=<mem>]"
    - walltime ... "#BSUB -W <walltime>"
    - cores    ... "#BSUB -n <cores>"

    Keys: g, G, i, L, cwd, outdir, p, s, S, sla, sp, T, U, u, v, e, eo, o, oo, 
    jobName will be submitted using::

        "#BSUB -<key> <value>"

    SLURM settings
    --------------

    For SLURM any provided key/value pair will be passed in the form:
    "#SBATCH --<key>=<value>"

    Some of the possible parameters to set are:

    - partition        ... The partition (queue) to use
    - nodes            ... Total number of nodes to run on
    - cpus-per-task    ... Number of cores per task
    - time             ... Maximum wall time DD-HH:MM:SS
    - constraint       ... Specific node architecture
    - mem-per-cpu      ... Memory requested per CPU in MB
    - mail-user        ... Email address to send notifications to
    - mail-type        ... On what events to send emails

    '''

    # --- check inputs
    if command is None and script is None:
        raise CommandError("schedule", "Missing parameter", "Either command or script need to be specified to run scheduler!")

    if command is not None and script is not None:
        raise CommandError("schedule", "Parameter conflict", "Only command or script need to be provided to run scheduler!")

    if scheduler_params is None:
        raise CommandError("schedule", "Missing parameter", "Scheduler parameters need to be provided to run scheduler!")

    # --- parse settings
    try:
        jobname   = scheduler_params.pop('jobname', "schedule")
        comname   = scheduler_params.pop('comname', "")
        jobnum    = scheduler_params.pop('jobnum', "")
    except:
        raise CommandError("schedule", "Misspecified parameter", "Could not parse the settings string:", scheduler_params)

    # --- compile command to pass
    if command is None:
        if not os.path.exists(script):
            raise CommandFailed("schedule", "File not found", "The specified script does not exist! [%s]" % (script))
        command = open(script, "r")

    if workdir is not None:
        if not os.path.exists(workdir):
            raise CommandFailed("schedule", "Folder does not exist", "The specified working directory does not exist! [%s]" % (workdir))
        command = "cd %s\n" % (workdir) + command

    if environment is not None:
        if not os.path.exists(environment):
            raise CommandFailed("schedule", "File not found", "The specified environment script does not exist! [%s]" % (environment))
        command = open(environment, "r") + "\n" + command

    # --- do search replace
    if replace is not None:
        replace = [e.strip().split(":") for e in replace.split("|")]

        for key, value in replace:
            command.replace("{{%s}}" % (key), value)

    # --- parse output
    outputs = {'stdout': None, 'stderr': None, 'both': None, 'return': None}

    if output is not None:
        for k, v in [[f.strip() for f in e.split(":")] for e in output.split("|")]:
            if not os.path.exists(os.path.dirname(v)) and k != 'return':
                raise CommandFailed("schedule", "Folder does not exist", "The specified folder for the '%s' log file does not exist! [%s]" % (k, os.path.dirname(v)), "Please check your paths!")
            outputs[k] = v
    else:
        # log name
        timestamp = datetime.now().strftime("%Y-%m-%d_%H.%M.%S.%f")

        if not slurm_array:
            logname = "/qunex_container_" + timestamp + ".txt"
        else:
            logname = "/qunex_container_job%a_" + timestamp + ".txt"

        # put in batchfolder
        if batchlogsfolder is not None:
            outputs['stdout'] = batchlogsfolder + logname
            outputs['stderr'] = batchlogsfolder + logname
        else:
            homedir = os.path.expanduser("~")
            outputs['stdout'] = homedir + logname
            outputs['stderr'] = homedir + logname

    if outputs['both'] is not None:
        outputs['stderr'] = outputs['both']
        outputs['stdout'] = outputs['both']

    # --- build scheduler commands
    s_command = ""

    if scheduler_name == "PBS":
        for k, v in scheduler_params.items():
            if k in ('mem', 'walltime', 'software', 'file', 'procs', 'pmem', 'feature', 'host', 'naccesspolicy', 'epilogue', 'prologue', 'select'):
                s_command += "#PBS -l %s=%s\n" % (k, v)
            elif k in ('j', 'm', 'o', 'S', 'a', 'A', 'M', 'q', 't', 'e', 'l'):
                s_command += "#PBS -%s %s\n" % (k, v)
            elif k == 'depend':
                s_command += "#PBS -W depend=%s\n" % (v)
            elif k == 'umask':
                s_command += "#PBS -W umask=%s\n" % (v)
            elif k == 'N' and jobname == 'schedule':
                jobname = v
            elif k == 'nodes':
                s_command += "#PBS -l nodes=%s\n" % v

        # job name
        if (comname != ""):
            jobname = "%s-%s" % (jobname, comname)
        if (jobnum != ""):
            jobname = "%s(%s)" % (jobname, jobnum)
        s_command += "#PBS -N %s\n" % jobname

        if outputs['stdout'] is not None:
            s_command += "#PBS -o %s\n" % (outputs['stdout'])
        if outputs['stderr'] is not None:
            s_command += "#PBS -e %s\n" % (outputs['stderr'])
        if outputs['both']:
            s_command += "#PBS -j oe\n"
        com = 'qsub'

    elif scheduler_name == "SLURM":
        s_command += "#!/bin/sh\n"
        for key, value in scheduler_params.items():
            if key in ('J', 'job-name') and jobname == 'schedule':
                jobname = v
            elif value == "QX_FLAG":
                s_command += "#SBATCH --%s\n" % (key.replace('--', ''))

            else:
                s_command += "#SBATCH --%s=%s\n" % (key.replace('--', ''), value)

        # set default cpus-per-task
        if ("cpus-per-task" not in scheduler_params.keys() and "c" not in scheduler_params.keys()):
            s_command += "#SBATCH --cpus-per-task=%s\n" % (parsessions * parelements)

        # jobname
        if (comname != ""):
            jobname = "%s-%s" % (jobname, comname)
        if (jobnum != ""):
            jobname = "%s(%s)" % (jobname, jobnum)
        s_command += "#SBATCH --job-name=%s\n" % jobname

        if outputs['stdout'] is not None:
            s_command += "#SBATCH -o %s\n" % (outputs['stdout'])
        if outputs['stderr'] is not None:
            s_command += "#SBATCH -e %s\n" % (outputs['stderr'])
        com = 'sbatch'

    # --- run the scheduler
    print("\nSubmitting:\n------------------------------")
    print(s_command)
    print(command + "\n")

    if outputs['return'] is None:
        serr = None
        sout = None
    elif outputs['return'] == 'both':
        serr = subprocess.STDOUT
        sout = subprocess.PIPE
    elif outputs['return'] == 'stderr':
        serr = subprocess.PIPE
        sout = None
    elif outputs['return'] == 'stdout':
        serr = None
        sout = subprocess.PIPE

    run = subprocess.Popen(com, shell=True, stdin=subprocess.PIPE, stdout=sout, stderr=serr, close_fds=True)
    run.stdin.write((s_command + command).encode('utf-8'))
    run.stdin.close()

    # ---- returning results
    if outputs['return'] in ['both', 'stdout']:
        result = run.stdout.read()
        return result
    elif outputs['return'] in ['stderr']:
        result = run.stderr.read()
        return result


def get_sessionids_from_batch(filename, batchfilter=None):
    '''
    get_sessionids_from_batch(filename, batchfilter=None)

    An internal function for reading batch.txt files. It reads the file and
    returns a list of sessions with the information on images and the additional
    parameters specified in the header.

    It returns only the sessions that match the provided filter.
    '''

    if not os.path.exists(filename):
        print("\n\n=====================================================\nERROR: Batch file does not exist [%s]", file=filename)
        raise ValueError("ERROR: Batch file not found: %s" % (filename))

    s = open(filename, "r").read()
    s = s.replace("\r", "\n")
    s = s.replace("\n\n", "\n")
    s = re.sub("^#.*?\n", "", s)

    s = s.split("\n---")
    s = [e for e in s if len(e) > 10]

    sessionids = []

    # build the filter dictionary
    filters_dict = {}

    # did we provide a filter
    if batchfilter is not None:
        # split filter items
        filters = batchfilter.split('|')

        # iterate through them and store them
        for f in filters:
            f_split = f.split(':')
            filters_dict[f_split[0]] = f_split[1]

    for sub in s:
        sub = sub.split('\n')
        sub = [e.strip() for e in sub]
        sub = [e.split("#")[0].strip() for e in sub]
        sub = [e for e in sub if len(e) > 0]

        # variable for storing the session id
        session = ""
        for line in sub:
            line = [e.strip() for e in line.split(":")]

            # filter 
            if len(line) == 2:
                # is it the id/session line
                if line[0] == "id" or line[0] == "session":
                    session = line[1]

                    # should I filter
                    if filters_dict and line[0] in filters_dict:
                        active_filter = filters_dict[line[0]].split(',')
                        if line[1] in active_filter or re.match(filters_dict[line[0]], line[1]):
                            sessionids.append(session)
                            break
                    else:
                        sessionids.append(session)
                        break

    return sessionids


def get_sessionids(batchfile, sessions, batchfilter=None):
    '''
    get_sessionids(batchfile, sessions, batchfilter=None)

    An internal function for getting a list of session ids.

    The batchfile parameter points to the location of the batch file.

    The batchfilter parameters is used for selecting a subset of sessions
    from the batch file.

    Sessions can be:
    - a comma, space or pipe separated list of session id codes,
    - a path to a *.list file (identified by .list extension).
    '''

    sessionids = None

    # session have a higher priority
    if sessions is not None:
        if re.match(".*\.list$", sessions):
            if os.path.isfile(sessions):
                sessionids = get_sessionids_from_list(sessions)
            else:
                raise ValueError("ERROR: The specified file is not found! [%s]!" % batchfile)
        else:
            sessionids = [e.strip() for e in re.split(' +|,|\|', sessions.replace(" ", ""))]
    # batchfile
    elif batchfile is not None:
        if os.path.isfile(batchfile):
            sessionids = get_sessionids_from_batch(batchfile, batchfilter)
        else:
            raise ValueError("ERROR: The specified file is not found! [%s]!" % batchfile)

    return sessionids


def get_sessionids_from_list(filename):
    '''
    get_sessionids_from_list(filename)

    An internal function for reading list files. It reads the file and
    returns a list of session ids.

    '''

    if not os.path.exists(filename):
        print("\n\n=====================================================\nERROR: List file does not exist [%s]", file=filename)
        raise ValueError("ERROR: List file not found: %s" % (filename))

    sessionids  = []

    with open(filename) as f:
        for line in f:
            if line.strip()[:1] == "#":
                continue

            line = [e.strip() for e in line.split(":")]

            if len(line) == 2 and line[0] == "subject id":
                sessionids.append(line[1])

    return sessionids


def get_batchlogs_folder(sessionsfolder):
    """
    ``deduceFolders(args)``

    Tries to deduce the location of study specific folders based on the provided
    arguments. For internal use only.
    """

    # extract folder
    f = os.path.abspath(sessionsfolder)

    # basefolder
    basefolder = None

    # try to find the root
    while os.path.dirname(f) and os.path.dirname(f) != '/':
        f = os.path.dirname(f)
        if os.path.exists(os.path.join(f, '.qunexstudy')):
            basefolder = f
            break
        elif os.path.exists(os.path.join(f, '.mnapstudy')):
            basefolder = f
            break
    
    # log folder
    batchlogsfolder = None

    if basefolder is not None:
        batchlogsfolder = os.path.join(basefolder, 'processing', 'logs', 'batchlogs')

    return batchlogsfolder


def main(args=None):
    """
    qunex_container is a self-standing command that can run QuNex commands 
    against an Apptainer or a Docker QuNex container. To run an QuNex command 
    against a container the basic call is::

        qunex_container <qunex command> [parameters] \
        --container="<a path to the Apptainer image or a Docker container name>" [additional options]
    
    `qunex command` is any command supported by QuNex. `parameters` are any
    parameters that should be passed to the qunex command. This part is the same
    as running::

        qunex <qunex command> [parameters]

    from within a container or on a self-standing QuNex installation. For list 
    of commands and their parameters consult QuNex online or in-line 
    documentation.

    Additionally qunex_container accepts the following parameters:

    INPUTS
    ======

    --container     specifies either the path to the Apptainer container image 
                    or the full specification of the Docker container to be used
                    (e.g. qunex/qunex_suite:0_45_07). This parameter can be 
                    omitted if the value is specified in the `QUNEXCONIMAGE` 
                    environmental variable.
    --bash_pre      If any additional commands have to be run in bash before the
                    execution of qunex_container command itself. Use a semicolon
                    separated list to chain multiple commands. ['']
    --bash_post     Used if any additional commands have to be run inside the
                    QuNex container before executing the desired QuNex command.
                    Use a semicolon separated list to chain multiple commands. 
                    ['']
    --bind          Used for binding external folder for execution via an 
                    Apptainer container, this is analog to the Apptainer's 
                    -B flag. ['']
    --nocleanenv    By default QuNex will use the --cleanevn flag of Apptainer
                    so your local environment setup will not be propagated into
                    the container. If you want to disable this functionality use
                    this flag. The flag is not set by default.
    --nv            Required when using CUDA inside Apptainer (Singularity). If
                    provided then apptainer exec --nv option will be used.
    --cuda_path     Required when using Apptainer (Singularity) and a CUDA
                    version that is not the QuNex default.
    --script        If a script is to be run against the Apptainer (Singularity)
                    container rather than a single command, the path to the
                    script to be run is specified here. ['']
    --envars        If environment variables other than the default set by the
                    container are to be used, they can be specified in a pipe
                    separated string formatted as:
                    "<variable>=><value>|<variable>=><value>"
                    Note that only the variables recognized by the QuNex suite
                    will be appropriately parsed and used in the container.
    --dockeropt     A string that lists the additional options to be used when
                    running the Docker container. If the parameter is ommited, 
                    the content of `QUNEXDOCKEROPT` environment variable will
                    be used. If neither is specified, the container will mount
                    the current as `data` by specifying the following options::

                        '-v "$(pwd)":/data'
                    
                    The parameters are to be specified in a string exactly as 
                    they would be on a command line, e.g. to run in detached
                    mode and mount a specific folder use::

                        "-d -v /host/directory:/container/directory"
    --scheduler     A string that specifies the details to use to submit the 
                    container job to a scheduling system. 
    --output        A string specifying where to redirect the standard output 
                    and error when using the scheduler. See "Redirecting 
                    output" for details!
    --parjobs       Specify the maximum amount of jobs that will be created
                    and run in parallel. By default this equals the number
                    of sessions your provided.
    --parsessions   Specify the amount of sessions that will be run in parallel
                    inside each created job. [1]
    --parelements   Specify the amount of elements that will be run in parallel
                    inside each session (for example BOLDs in hcp_fmri_volume).
                    [1]
    --parinfo       If this flag is set then qunex_container will not execute
                    the command, it will only printout the parallelism
                    information, e.g. how many jobs will be spawned, how many
                    sessions will be run in parallel, etc.

    RESULTS
    =======

    `qunex_container` will compile a temporary file with the relevant commands to 
    submit to the container. The file will be created in the users home folder
    and will be deleted as the last action completed by the container. In case 
    of a Docker container, to give access to the compiled script, the user's 
    home folder will be mounted as `/root` in the container, which is the home
    folder within the container.

    If a script parameter is specified, in case of an Apptainer container, the 
    script will be executed using the `bash <script>` command. In case of a 
    Docker container, the content of the script will be appended to the 
    temporary script generated by the `qunex_container`. Do note that in the 
    case of the Apptainer container the script can reference paths on the 
    host computer, whereas in the case of the Docker container, the script
    has to reference the paths and mounts as they are visible within the
    Docker container. 


    Scheduling jobs
    ---------------

    Container commands can be submitted to a scheduling system by specifying 
    the `--scheduler` parameter with a settings string. The settings string 
    should be a comma separated list of parameters. The first parameter has to 
    be the scheduler name (PBS, LSF, SLURM), the rest of the parameters are 
    key-value pairs that are to be passed as settings to the scheduler. 
    Additional parameters common to all the schedulers can be specified:

    - jobname ... the name of the job to run
    - comname ... the name of the command the job runs
    - jobnum  ... the number of the job being run

    Example settings strings::

        "SLURM,jobname=hcp_freesurfer,time=03-24:00:00,cpus-per-task=2,mem-per-cpu=2500,partition=pi_anticevic"
        "LSF,jobname=DWIproc,jobnum=1,cores=20,mem=250000,walltime=650:00,queue=pi_anticevic"


    Scheduling multiple jobs in parallel
    ------------------------------------
    
    If the parameters provided include --parjobs, --parsessions, --scheduler
    and --sessions or --batchfile, then qunex_container will spread the execution
    of the command by scheduling multiple jobs to run on separate nodes. Specifically,
    if --parjobs is not provided then QuNex will schedule a job for each of the
    sessions. If --parjobs is provided then QuNex will schedule at most the
    requested amount of jobs, inside each job QuNex will run at most
    --parsessions in parallel.  E.g. if 10 sessions are specified, parjobs
    is set to 3 and parsessions is set to 4, QuNex will schedule 3 jobs. The first
    job will run 4 sessions in parallel and the other 2 jobs will run 3 sessions
    in parallel.


    Redirecting output
    ------------------

    By default, QuNex will try to put scheduler logs into the
    <study>/processing/logs/batchlogs folder. If not possible QuNex will put them
    in your home folder. You can also put them in a custom location by specifying
    the `output` parameter. The parameter supports three different directives
    provided by "<key>:<value>" pairs in a pipe separated string:

    stdout
        specifies a path to a log file that should store standard output of the 
        submitted job
    stderr
        specified a path to a log file that should store error output of the 
        submitted job
    both
        specifies a path to a log file that should store joint standard and 
        error outputs of the submitted job

    Examples:

    - "stdout:processing.log"
    - "stdout:processing.output.log|stderr:processing.error.log"
    - "both:processing.log"

    Do not specify error and standard outputs both using --output parameter and
    scheduler specific options within settings string. It is best to provide 
    full absolute paths to the desired log.


    EXAMPLE USE
    ===========

    ::

        qunex_container hcp_freesurfer \\
        --sessionsfolder=/data/study/sessions \\
        --batchfile=/data/study/processing/batch.txt \\
        --parsessions=4 \\
        --container=/apptainer/qunex_suite-0_38_10.sif \\
        --scheduler="SLURM,time=2-00:00:00,cpus-per-task=2,mem-per-cpu=15000,partition=pi_anticevic"

    """

    if args is None:
        args = sys.argv[1:]

    if not args:
        print(main.__doc__)
        exit()

    # deprecation warnings, TODO remove in 1.0.0
    for arg in args:
        if "sessionids=" in arg:
            print("WARNING: The sessionids parameter will be deprecated, use the sessions parameter to select sessions.")
        if "sessions=" in arg and ".txt" in arg:
            print("WARNING: It seems like you are using the sessions parameters to pass the location of the batch file to QuNex. This functionality will be deprecated, use the batchfile parameter for specifying the location of the batchfile.")

    env_status          = False
    scheduler           = None
    conimage            = None
    command             = ""
    bash_pre            = None
    bash_post           = None
    bind                = None
    nocleanenv          = None
    nv                  = None
    cuda_path           = None
    script              = None
    parjobs             = None
    parsessions         = 1
    parelements         = 1
    batchfile           = None
    batchfilter         = None
    sessions            = None
    sessionsfolder      = None
    sessionids          = None
    envars              = None
    dockeropt           = None
    output              = None
    parinfo             = None
    overwrite           = None

    for arg in args:
        if "env_status" in arg or "envstatus" in arg:
            env_status = True
        if "scheduler=" in arg:
            k, scheduler = arg.split("=", 1)
        elif "container=" in arg:
            k, conimage = arg.split("=", 1)
        elif "envars=" in arg:
            k, envars = arg.split("=", 1)
        elif "dockeropt=" in arg:
            k, dockeropt = arg.split("=", 1)
        elif "output=" in arg:
            k, output = arg.split("=", 1)
        elif "bash_pre=" in arg:
            k, bash_pre = arg.split("=", 1)
        elif "bash_post=" in arg:
            k, bash_post = arg.split("=", 1)
        elif "bind=" in arg:
            k, bind = arg.split("=", 1)
        elif arg == "--nocleanenv":
            nocleanenv = True
        elif arg == "--nv":
            nv = True
        elif "cuda_path=" in arg:
            k, cuda_path = arg.split("=", 1)
        elif "script=" in arg:
            k, script = arg.split("=", 1)
        elif "parjobs=" in arg:
            k, parjobs = arg.split("=", 1)
            parjobs = int(parjobs)
        elif "parsessions=" in arg:
            k, parsessions = arg.split("=", 1)
            command += '%s="%s" ' % (k, parsessions)
            parsessions = int(parsessions)
        elif "parelements=" in arg:
            k, parelements = arg.split("=", 1)
            command += '%s="%s" ' % (k, parelements)
            parelements = int(parelements)
        elif "sessionsfolder=" in arg:
            k, sessionsfolder = arg.split("=", 1)
            command += '%s="%s" ' % (k, sessionsfolder)
        elif "sessions=" in arg:
            k, sessions = arg.split("=", 1)
        elif "batchfile=" in arg:
            k, batchfile = arg.split("=", 1)
        elif "filter=" in arg:
            k, batchfilter = arg.split("=", 1)
        elif "sessionids=" in arg:
            k, sessionids = arg.split("=", 1)
        elif "overwrite=" in arg:
            k, overwrite = arg.split("=", 1)
            command += '%s ' % (arg)
        elif "=" in arg:
            k, v = arg.split('=', 1)
            command += '%s="%s" ' % (k, v)
        elif arg.replace("-", "") == "parinfo":
            parinfo = True
        else:
            command += '%s ' % (arg)

    # workaround for commands that are not supported
    commands_blacklist = [
        'create_batch',
        'create_list',
        'create_conc',
        'gather_behavior',
        'pull_sequence_names',
        'create_stats_report',
        'fc_compute_roifc',
        'fc_compute_gbc',
        'fc_compute_seedmaps',
        'fc_extract_roi_timeseries',
        'general_extract_roi_values',
        'general_extract_roi_glm_values'
    ]
    qx_command = command.split(' ')[0]
    # ban parallel execution of these commands
    if overwrite == "yes" and parsessions > 1 and qx_command in commands_blacklist:
        print("ERROR: Parallel execution of this command is not supported when overwrite is set to yes!")
        exit(1)

    # batchlogs folder
    batchlogsfolder = None
    if sessionsfolder is not None:
        batchlogsfolder = get_batchlogs_folder(sessionsfolder)

    if conimage is None:
        if "QUNEXCONIMAGE" in os.environ:
            conimage = os.environ['QUNEXCONIMAGE']
        else:
            print("ERROR: No Apptainer image or Docker container name specified either in the command line or as a QUNEXCONIMAGE environment variable!")
            exit(1)

    # Docker or Apptainer
    apptainer = conimage.endswith(".simg") or conimage.endswith(".sif")

    # just report env status and quit
    if env_status:
        # apptainer
        if apptainer:
            env_command = "singularity exec %s bash /opt/qunex/env/qunex_container_env_status.sh" % conimage

        # docker
        else:
            env_command = "docker run %s bash -c \"/opt/qunex/env/qunex_container_env_status.sh\"" % conimage

        # run
        subprocess.Popen(env_command, shell=True)
        exit(0)

    if command.startswith('?scheduler'):
        print(schedule.__doc__)
        exit()

    # -- check for environment variables
    if envars:
        envars = [e for e in envars.split('|')]
        envars = [e.split('=>') for e in envars if '=>' in e]
    else:
        envars = []

    # -- check for docker options
    if dockeropt is None:
        if "QUNEXDOCKEROPT" in os.environ:
            dockeropt = os.environ['QUNEXDOCKEROPT']
        else:
            dockeropt = "-v \"$(pwd)\":/data"

    homedir = os.path.expanduser("~")
    dockeropt += " -v %s:%s" % (homedir, homedir)

    # bind cuda path if provided
    if cuda_path:
        dockeropt += f" -v {cuda_path}:/usr/local/cuda/"

    # if sessions is a batch file set as batchfile
    old_sessions_naming = False
    if sessions is not None and ".txt" in sessions:
        if batchfile is not None:
            print("ERROR: It seems like you passed the batchfile both through the sessions and the batchfile parameters!")
            exit(1)
        else:
            batchfile = sessions
            sessions = sessionids
            sessionids = None
            old_sessions_naming = True
    elif sessions is not None and sessionids is not None:
            print("WARNING: It seems like you are passing a list of sessions both through the sessions parameter and through the sessionids parameter!")

    # number of sessions
    n_sessions = None

    # get sessionsids
    g_sessionids = get_sessionids(batchfile, sessions, batchfilter)
    if g_sessionids:
        n_sessions = len(g_sessionids)

    # do not run in parallel multi_session/longitudinal commands
    multi_session_command = False
    multi_commands = ["hcp_longitudinal_freesurfer", "hcp_temporal_ica", "hcp_make_average_dataset"]
    if any(c in command for c in multi_commands):
        multi_session_command = True

    # are we using SLURM array, not by default
    slurm_array = False

    # init scheduler params
    if scheduler is not None:
        scheduler_params_list = [e.strip() for e in scheduler.split(",")]
        scheduler_name = scheduler_params_list.pop(0)

        # check scheduler
        if scheduler_name not in ['PBS', 'LSF', 'SLURM']:
            raise CommandError("schedule", "Misspecified parameter", "First value in the settings string has to specify one of PBS, LSF, SLURM!", "The settings string submitted was:", scheduler_name)

        # parse scheduler parameters
        scheduler_params = {}
        for s in scheduler_params_list:
            # parameters with values
            if "=" in s:
                sSplit = s.split("=", 1)

                # SLURM job array?
                if scheduler_name == "SLURM" and sSplit[0].strip() == "array":
                    slurm_array = True
            
                scheduler_params[sSplit[0].strip()] = sSplit[1].strip()
            # flags
            else:
                # SLURM job array?
                if scheduler_name == "SLURM" and s.strip() == "array":
                    n_jobs = 1
                    if n_sessions is not None:
                        n_jobs = n_sessions - 1
                    slurm_array = True
                    if parjobs is None:
                        scheduler_params["array"] = "0-%s" % (n_jobs)
                    else:
                        scheduler_params["array"] = "0-%s%%%s" % (n_jobs, parjobs)
                else:
                    scheduler_params[s.strip()] = "QX_FLAG"

        # if job array we have a single job
        if slurm_array:
            parjobs = 1

            # only allow HCP MPP commands with job array
            array_commands = [
                'hcp_pre_freesurfer',
                'hcp_freesurfer',
                'hcp_post_freesurfer',
                'hcp_fmri_volume',
                'hcp_fmri_surface'
            ]
            if qx_command not in array_commands:
                print("ERROR: SLURM job arrays are supported only for HCP Minimal Preprocessing Pipelines!")
                print("         ... hcp_pre_freesurfer, hcp_freesurfer, hcp_post_freesurfer, hcp_fmri_volume and hcp_fmri_surface.")
                exit(1)

    # array for storing session ids
    sessionids_array = []

    # if scheduler is not None and we do not have a multi_session_command then setup parallelism
    if scheduler is not None and (sessions is not None or batchfile is not None) and not multi_session_command:
        # if parjobs is None each session is its own job
        if parjobs is None:
            parjobs = 0

            # split to chunks
            for i in range(0, n_sessions, parsessions):
                sessionids_array.append(','.join(g_sessionids[i:i + parsessions]))

            # calculate the number of parallel jobs
            parjobs = len(sessionids_array)

        # else split jobs into chunks
        else:
            # how big are chunks of sessions
            chunks = int(math.ceil(n_sessions / float(parsessions)))

            # if chunks is lower then parjobs tweak parjobs
            if chunks < parjobs:
                parjobs = chunks

            # init queues
            sessionids_arrays = [[] for _ in range(parjobs)]

            # divide sessions among jobs
            for idx, sessionid in enumerate(g_sessionids):
                job_id = idx % parjobs
                sessionids_arrays[job_id].append(sessionid)
            
            for s in sessionids_arrays:
                sessionids_array.append(",".join(s))

    else:
        # do not run in parallel
        parjobs = 1

        # add session ids
        if g_sessionids is not None:
            sessionids_array.append(",".join(g_sessionids))

    # print out details
    if scheduler:
        print("    Qunex will schedule %s jobs" % parjobs)

    if n_sessions is not None:
        print("\n--> QuNex will run the command over %s sessions. It will utilize:\n" % n_sessions)
        print("    Maximum sessions run in parallel for a job: %s." % parsessions)
        print("    Maximum elements run in parallel for a session: %s." % parelements)
        print("    Up to %s processes will be utilized for a job.\n" % (parelements * parsessions))

        if slurm_array:
            print("    Using SLURM job array over sessions: %s" % sessionids_array[0])
        else:
            for i in range(0, parjobs):
                print("    Job #%s will run sessions: %s" % ((i + 1), sessionids_array[i]))

    # execute
    if parinfo is None:
        for i in range(0, parjobs):
            qx_command = command

            # add batchfile to command?
            if batchfile is not None:
                if not old_sessions_naming:
                    qx_command += '--batchfile="%s" ' % (batchfile)
                else:
                    qx_command += '--sessions="%s" ' % (batchfile)

            # add sessions to command?
            if i < len(sessionids_array):
                if not old_sessions_naming:
                    qx_command += '--sessions="%s" ' % (sessionids_array[i])
                else:
                    qx_command += '--sessionids="%s" ' % (sessionids_array[i])

            # setup script
            timestamp = datetime.now().strftime("%Y-%m-%d_%H.%M.%S.%f")
            # prepare the schedule file
            if batchlogsfolder is not None:
                script_path = os.path.join(batchlogsfolder, f'qunex_container_command_{timestamp}.sh')
            else:
                script_path = os.path.join(homedir, f'qunex_container_command_{timestamp}.sh')

            f = open(script_path, "w")

            for k, v in envars:
                print("export con_%s=\"%s\"" % (k, v), file=f)

            print("source /opt/qunex/env/qunex_environment.sh", file=f)

            if bash_post:
                print(bash_post, file=f)

            if script:
                if apptainer:
                    print("bash " + script, file=f)
                else:
                    with open(script, 'r') as sfile:
                        for line in sfile:
                            print(line, file=f)
            elif 'runTurnkey' in qx_command:
                qx_command = qx_command.replace('runTurnkey', '')
                print("bash /opt/qunex/bash/qx_utilities/run_turnkey.sh" + qx_command, file=f)
            elif 'run_turnkey' in qx_command:
                qx_command = qx_command.replace('run_turnkey', '')
                print("bash /opt/qunex/bash/qx_utilities/run_turnkey.sh" + qx_command, file=f)
            else:
                print("bash /opt/qunex/bin/qunex.sh " + qx_command, file=f)

            f.close()

            # setup the container command
            container_command = ""
            if bash_pre:
                container_command += bash_pre + ";"

            if apptainer:
                container_command += "singularity exec "

                # no clean env
                if nocleanenv is None:
                    container_command += "--cleanenv "
                    if slurm_array:
                        # the params we need are SLURM_ARRAY_TASK_ID and SLURM_ARRAY_TASK_MAX
                        # we do not need SLURM_JOB_ID, SLURM_ARRAY_JOB_ID, SLURM_ARRAY_TASK_COUNT, SLURM_ARRAY_TASK_MAX for now
                        slurm_array_params = ['SLURM_ARRAY_TASK_ID', 'SLURM_ARRAY_TASK_MAX']
                        # pass variables into the Apptainer container
                        container_command += '--env '
                        container_command += ','.join(['%s=${%s}' % (p, p) for p in slurm_array_params])
                        # replace trailing comma with space
                        container_command += ' '

                # nv
                if nv:
                    container_command += " --nv "

                # bind
                if bind:
                    container_command += "-B %s " % bind

                # bind cuda path if provided
                if cuda_path:
                    if not bind:
                        container_command += f"-B {cuda_path}:/usr/local/cuda/ "
                    else:
                        container_command += f",{cuda_path}:/usr/local/cuda/ "

                container_command +=  "%s bash %s" % (conimage, script_path)
            else:
                container_command = "docker run %s %s bash %s" % (dockeropt, conimage, script_path)

            if scheduler:
                schedule(command=container_command, scheduler_name=scheduler_name, scheduler_params=scheduler_params.copy(), output=output, parsessions=parsessions, parelements=parelements, batchlogsfolder=batchlogsfolder, slurm_array=slurm_array)
            else:
                subprocess.Popen(container_command, shell=True)

if __name__ == "__main__":
    main()
