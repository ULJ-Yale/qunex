#!/usr/bin/env python2.7
# encoding: utf-8

import os.path
import sys
import copy
import datetime
from general import scheduler as gs
from general import utilities as gu
from general import process as gp
from general import matlab as gm
from general import core as gc
from general import exceptions as ge
from general import commands as gcom
from general import commands_support as gcs


# --- Get current QuNex Suite version and prepend to help calls
tools     = os.environ['TOOLS']
qunexrepo = os.environ['QUNEXREPO']
with open(os.path.join(tools, qunexrepo, 'VERSION.md'), "r") as f:
    version  = f.read().strip()
print "Quantitative Neuroimaging Environment & Toolbox (QuNex) Suite Version", version
print 

help = '''
  QuNex python utilities (python qx_utilities) for Preprocessing and Analyses   
--------------------------------------------------------------------------------

 DESCRIPTION: QuNex Suite workflows contain python-based general neuroimaging 
 utilities. QuNex python utilities can be invoked via the "qunex <command>" call.

                        General QuNex Usage Syntax
================================================================================

 qunex <command> \
   --parameterA=<value> \
   [--parameterB=<value>]
  =>  --   Dashes or "flags" denote parameters.
  =>  []   Square brackets denote optional parameters. 
             Note: What is shown inside [] denotes default values of optional parameters. 
  =>  <>   Angle brackets denote user-specified values for a given parameter.
  => commands, parameters and values are shown in small or "camel" case.

'''

#
# Took out these two functions until fully integrated to avoid documentation confusion w/ bash qx_utilities
# Also these should not be referenced as 'hcp' functions as they are not
#
# hcp_dtifit    Run FSL DTI fit.
# hcp_bedpostx  Run FSL Bedpostx GPU.

comlist = r'''
  QuNex python utilities (python qx_utilities) for Preprocessing and Analyses   
--------------------------------------------------------------------------------


DICOM commands
--------------
list_dicom      [folder=.]
split_dicom     [folder=.]
sort_dicom      [folder=.]
dicom2nii       [folder=.] [clean=ask] [unzip=ask] [gzip=ask] [verbose=True] [parelements=1]
dicom2niix      [folder=.] [clean=ask] [unzip=ask] [gzip=ask] [sessionid=None] [verbose=True] [parelements=1] [tool=auto]
import_dicom    [sessionsfolder=.] [inbox=<sessionsfolder>/inbox/MR] [check=yes] [pattern=".*?(OP[0-9.-]+).*\.zip"] [tool=auto] [parelements=1] [logfile=""] [archive=move] [verbose=yes]
get_dicom_info  dicomfile=<dicom_file> [scanner=siemens]


Import commands
---------------
import_bids     [sessionsfolder=.] [inbox=<sessionsfolder>/inbox/BIDS] [action=link] [overwrite=no] [archive=move] [bidsname=<inbox folder name>]
map_bids2nii    [sourcefolder='.'] [overwrite='no']
import_hcp      [sessionsfolder=.] [inbox=<sessionsfolder>/inbox/HCPLS] [action=link] [overwrite=no] [archive=move] [hcplsname=<inbox folder name>]
map_hcpls2nii   [sourcefolder='.'] [overwrite='no']


WUSTL NIL pipeline commands
---------------------------
run_nil         [folder=.] [overwrite=no] [sourcefile=session.txt]
run_nil_folder  [folder=.] [pattern=OP*] [overwrite=no] [sourcefile=session.txt]


General image file commands
---------------------------
slice_image     sourcefile=<source image> targetfile=<target image> [frames=1]


NIfTI file conversion commands
------------------------------
fz2zf           inf=<input_image> [outf=<output_image>]
reorder         inf=<input_image> [outf=<output_image>]
reslice         inf=<input_image> slices=<slices_per_volume> [outf=<output_image>]
printniftihdr   <image_filename>
modniftihdr     <image_filename> <modification string>
nifti24dfp      inf=<input_filename> [outf=<output_filename>]


HCP setup commands
------------------
create_session_info sessions=<sessions specification> [pipelines=hcp] [sessionsfolder=.] [sourcefile=session.txt] [targetfile=session_*.txt] [mapping=specs/*_mapping.txt] [filter=None] [overwrite=no]
setup_hcp           [sourcefolder=.] [targetfolder=hcp] [sourcefile=session_*.txt] [check="yes"] [existing="add"] [hcp_filename="standard"] [folderstructure="hcpls"] [hcp_suffix=""]


Miscellaneous file commands
---------------------------
create_study    studyfolder=<path to study base folder> [subfolders=$TOOLS/python/qx_utilities/templates/study_folders_default.txt]
create_batch    [sessionsfolder=.] [sourcefiles=session_*.txt] [targetfile=processing/batch.txt] [sessions=None] [filter=None] [overwrite=ask] [paramfile=<sessionsfolder>/specs/batch.txt]
create_list     [sessionsfolder=.] [sessions=None] [filter=None] [listfile=None] [bolds=None] [conc=None] [fidl=None] [glm=None] [roi=None] [boldname="bold"] [boldtail=".nii.gz"] [overwrite="no"] [check="yes"]
create_conc     [sessionsfolder=.] [sessions=None] [filter=None] [concfolder=None] [concname=""] [bolds=None] [boldname="bold"] [boldtail=".nii.gz"] [overwrite="no"] [check="yes"]
run_list        listfile=<path to runlist file> runlists=<name(s) of the list(s) to run> [logfolder=None]


FIDL file commands
-------------------
join_fidl           concfile=<reference_concfile> fidlroot=<fidl_files_root_pattern> [fidlname=<optional fidlname to append>]
join_fidl_folder    concfolder=<folder_with_concfiles> [fidlfolder=<folder_with_fidl_files>] [outfolder=<folder in which to save joint files>] [fidlname=<optional fidl name to append>]
split_fidl          concfile=<reference_concfile> fidlfile=<fidl_file_to_split> [outfolder=<folder_to_save_results>]
check_fidl          [fidlfile=] [fidlfolder=.] [plotfile=] [allcodes=false]


Workbench surface mapping commands
----------------------------------
map2pals    volume=<volume file> metric=<metric file> [atlas=711-2C] [method=interpolated] [mapping=afm]
map2hcp     volume=<volume file> [method=trilinear]
mask_map    image=<image file> masks=<list of masks to use> [output=<output image name>] [minv=<list of thresholds>] [maxv=<list of thresholds>] [join=<OR or AND>]
join_maps   images=<image file list> output=<output file name> [names=<volume names list>] [originals=<remove or keep>]


PALM commands
--------------
create_ws_palm_design   factors=<factor string> nsubjects=<number of subjects> root=<design root name>
run_palm                image=<image file(s)> [design=<design string>] [args=<arguments string>] [root=<root name for the output>] [options=<options string>] [parelements=<number of proceeses to run in parallel>]  [overwite=no]


Scheduling command
------------------
schedule [command=<command string>] [script=<path to script>] \
         settings=<settings string> \
         [replace=<"key:value|key:value" string>] \
         [workdir=<path to working directory>] \
         [environment=<path to environment setup script>] \
         [output=<string specifying how to process output>]


Processing commands
-------------------
In contrast to commands listed above, processing commands can be submitted to
run on a computer cluster using either a PBS or LSF scheduling. The commands
operate on a list of sessions specified in a `batch.txt` file that provides
information about each session and his or her images and other information.
Options for the processing command can be specified either in the `batch.txt`
file or on the command line, the latter having priority if a parameter is
specified at both levels. No options need to be set for any of the commands
listed below. The key parameters with their default values are:

    --sessions=batch.txt    the path to the batch.txt file
    --sessionsfolder=.      the path to the study sessions folder
    --overwrite=no          whether to overwrite existing results
    --parsessions=1         how many sessions to run in parallel
    --nprocess=0            how many sessions to process (0=all)
    --log=remove            whether to remove logs of commands that have
                            ran and finished successfully
    --run=run               whether to run (run) the listed command or
                            test (test) if all the data is ready for the
                            specific command to run successfully

Please note that each of the commands can be run by specifying its short 
(listed first) or full (listed second) name followed by specfication of
processing options. 


HCP preprocessing commands
--------------------------
hcp_pre_freesurfer          Run HCP PreFreeSurfer pipeline.
hcp_freesurfer              Run HCP FreeSurfer pipeline.
hcp_post_freesurfer         Run HCP Post FreeSurfer pipeline.
hcp_fmri_volume             Run HCP fMRI Volume pipeline.
hcp_fmri_surface            Run HCP fMRI Surface pipeline.
hcp_icafix                  Run HCP ICAFix pipeline.
hcp_post_fix                Run HCP PostFix pipeline.
hcp_reapply_fix             Run HCP ReApplyFix pipeline.
hcp_msmall                  Run HCP MSMAll pipeline.
hcp_dedrift_and_resample    Run HCP MSMAll pipeline.
hcp_diffusion               Run HCP DWI pipeline.


FSL commands
--------------------------
fsl_f99                 Run FSL F99 command.
fsl_xtract              Run FSL XTRACT command.


Functional connectivity preprocessing commands
----------------------------------------------
map_hcp_data            Map HCP preprocessed data to sessions' image folder.
create_bold_brain_masks Create brain masks for BOLD runs.
compute_bold_stats      Compute BOLD movement and signal statistics.
create_stats_report     Create BOLD movement statistic reports and plots.
extract_nuisance_signal Extract nuisance signal from BOLD images.
preprocess_bold         Preprocess single BOLD images.
preprocess_conc         Preprocess conc bundles of BOLD images.


General purpose commands
------------------------
run_shell_script    Runs the specified script.


Legacy commands
---------------
run_basic_segmentation  Run basic structural image segmentation using BET and FAST.
get_fs_data             Copy existing FreeSurfer data to sessions' images folder.
run_subcortical_fs      Run subcortical freesurfer segmentation.
run_full_fs             Run full freesurfer segmentation


MATLAB commands supported via python qx_utilities
-------------------------------------------------
A number of MATLAB commands provided as part of QuNex can be  invoked via the
python qx_utilities engine. A list of commands currently supported is 
provided below. For more information run `qunex <command>`. 

Note that parameters can be specified in any order. Parameters that are not provided 
will be passed as empty and will be processed with default values. Take care to embed 
vectors in square brackets (e.g. "[1 8 6 12]") and cell arrays in curly braces 
(e.g. "{'DLPFC', 'ACC', 'FEF'}"). In addition, 'saveOutput' parameter can be specified 
to redirect Matlab output to a file: (e.g. "both:command.log" or "stdout:ok.log|stderr:error.log").

Example call of a QuNex MATLAB command:

 qunex general_find_peaks \\
  --fin='map_zstat.dscalar.nii' \\
  --fout='map_peaks.dscalar.nii' \\
  --mins="[50 50]" --maxs="[300 350]" \\
  --val=n t=3.5 \\
  --projection=midthickness


 ==> List of MATLAB commands supported via python qx_utilities:
'''

for mcom in gm.functionList:
    comlist += "\n " + mcom

def runCommand(command, args):

    folders = gc.deduceFolders(args)

    if folders['basefolder']:
        gu.checkStudy(folders['basefolder'])

    # --- check if command is deprecated
    command = gcs.check_deprecated_commands(command)

    # -- remap deprecated arguments
    args = gcs.check_deprecated_parameters(args, command)

    # --- sort commands by type
    if command in gcom.commands:
        pass
    elif command in gp.allactions:
        gp.run(command, args)
        return
    elif command in gm.functions:
        if 'scheduler' in args:
            gs.runThroughScheduler(command, sessions=None, args=args, parsessions=1, logfolder=folders['logfolder'])
        else:
            gm.run(command, args)
        return
    else:
        print "ERROR: Command %s not recognized. Please run gmri -l to see list of valid commands." % (command)
        sys.exit(1)

    # --- process commands
    # -- sort arguments
    bargs = {}
    eargs = {}
    for k, v in args.items():
        if k in gcom.commands[command]['args']:
            bargs[k] = v
        else:
            eargs[k] = v

    # -- check extra arguments, except for run_list
    if eargs and command != "run_list":
        bad = []
        for k, v in eargs.items():
            if k not in gcs.extra_parameters:
                bad.append(k)
                print "ERROR: Extra argument %s is not valid! Please check your command!" % (k)
        if bad:
            raise ge.CommandError("gmri", "Invalid arguments", "The extra argument(s) provided is/are not valid! [%s]" % (", ".join(bad)))

    # -- process extra arguments
    sessions = None
    if 'sessions' in eargs:
        if command != "run_list" and not any([e in gcom.commands[command]['args'] for e in ['sourcefolder', 'folder']]):
            raise ge.CommandError("gmri", "Incompatible command", "Command %s can not be run on multiple sessions!" % (command))
        if folders['sessionsfolder'] is None:
            folders['sessionsfolder'] = "."
        sessions, _ = gc.getSessionList(eargs['sessions'], filter=eargs.get('filter'), sessionids=eargs.get('sessionids'), sessionsfolder=folders['sessionsfolder'], verbose=False)

    logname = eargs.get('logname')

    calls = []

    # -- run_list specifics
    if command == "run_list":
        if sessions and 'sperlist' in eargs:

            if 'scheduler' in eargs:
                # -- define number of sessions to run in each run_list
                parsessions = int(eargs['sperlist'])
                args['parsessions'] = eargs['sperlist']
                if 'ignore' in args:
                    args['ignore'] += 'scheduler'
                else:
                    args['ignore'] = 'scheduler'
                del args['sperlist']

                gs.runThroughScheduler(command, sessions=sessions, args=args, parsessions=parsessions, logfolder=folders['logfolder'], logname=logname)
            
            else:
                # -- define number of sessions to run in each run_list
                sperlist = args['sperlist']
                del args['sperlist']

                # -- define number of run_list to run in parallel
                parsessions = eargs.get('runinpar', 1)
                args['parsessions'] = parsessions
                if 'runinpar' in args:
                    del args['runinpar']

                c = 0
                while sessions:
                    c += 1
                    largs = args.copy()

                    # -- set up a list of sessions to run in each run_list

                    slist = [sessions.pop(0)['id'] for e in range(sperlist) if sessions]
                    largs['sessionids'] = "|".join(slist)

                    calls.append({'name': 'run_list_%d' % (c), 'function': gcom.commands[command]['com'], 'args': largs, 'logfile': None})

        else:
            # -- if using a scheduler schedule the whole run_list commmand
            if 'scheduler' in eargs:
                if 'ignore' in args:
                    args['ignore'] += 'scheduler'
                else:
                    args['ignore'] = 'scheduler'

                runListFolder = folders['logfolder']

                # create folder if it does not exist
                if not os.path.isdir(runListFolder):
                    os.makedirs(runListFolder)

                runListFolder = os.path.join(runListFolder, "batchlogs")

                # create folder if it does not exist
                if not os.path.isdir(runListFolder):
                    os.makedirs(runListFolder)

                logstamp = datetime.datetime.now().strftime("%Y-%m-%d_%H.%M.%s")
                logname = os.path.join(runListFolder, "Log-%s-%s.log") % ("runlist", logstamp)

                gs.runThroughScheduler(command, args=args, logfolder=runListFolder, logname=logname)

            else:
                bargs['eargs'] = eargs
                gcom.commands[command]['com'](**bargs)
                print "\n===> Successful completion of task"

    # -- all other commands    
    else:
        parsessions = int(eargs.get('parsessions', '1'))

        # -- are we using a scheduler
        if 'scheduler' in eargs:
            gs.runThroughScheduler(command, sessions=sessions, args=args, parsessions=parsessions, logfolder=folders['logfolder'], logname=logname)

        # -- a basic call
        elif sessions is None:
            # logfolder
            if not folders['logfolder']:
                folders['logfolder'] = "."

            # createstudy exception
            if command == "create_study" and "studyfolder" in args:
                folders['logfolder'] = args["studyfolder"] + "/processing/logs"
            elif command == "create_study":
                folders['logfolder'] = "./processing/logs"

            # if case is provided
            sufix = ""
            if "sessions" in args:
                sufix = "_" + args["sessions"]

            logfile = os.path.join(folders['logfolder'], 'comlogs', "%s%s.log" % (command, sufix))

            # run without log for exceptions
            # remove logs for exceptions
            if command in gcs.logskip_commands:
                gcom.commands[command]['com'](**args)
            # run with log
            else:
                _, result, _, _ = gc.runWithLog(gcom.commands[command]['com'], args=args, logfile=logfile)

        # -- sessions loop
        else:
            for session in sessions:
                targs   = dict(bargs)
                name    = command + ": " + session['id']
                sessionsfolder = os.path.join(folders['sessionsfolder'], session['id'])
                if folders['logfolder']:
                    logfile = os.path.join(folders['logfolder'], 'comlogs', "%s_%s.log" % (command, session['id']))
                for targ in ['sourcefolder', 'folder']:
                    if targ in gcom.commands[command]['args']:
                        targs[targ] = sessionsfolder

                calls.append({'name': name, 'function': gcom.commands[command]['com'], 'args': targs, 'logfile': logfile})

    # -- Have we set up calls to run in parallel?
    if calls:
        callInfo = "Running %s" % (command)
        callInfo += "\n" + "".join(['=' for e in range(len(callInfo))])
        print callInfo
        
        print "\n===> Running %s through %d sessions in parallel" % (command, parsessions)

        results = gc.runInParallel(calls, cores=parsessions, prepend="     ... ")

        ok = True
        print "\n===> Final report for command", command
        results.sort(key=lambda x: x[0])
        for name, result, targetLog, prepend in results:
            if result:                
                ok = False
            else:
                result = 'completed'
            print "%s %s %s [log: %s]" % (prepend, name, result, targetLog)
        if ok:
            print "\n===> Successful completion of task"


def printHelp(com):

    # --- print list of gmri local commands
    if com == 'l':
        print comlist

    # --- print list of gmri local commands
    elif com == 'available':
        available_commands = []
        # -> gmri commands
        for c, _ in gcom.commands.iteritems():
            available_commands.append(c)
        # -> complex processing commands
        for l in gp.calist:
            if len(l):
                # deprecated command abbreviations 
                # print l[0]
                available_commands.append(l[1])
        # -> longitudinal processing commands
        for l in gp.lalist:
            if len(l):
                # deprecated command abbreviations 
                # print l[0]
                available_commands.append(l[1])
        # -> simple processing commands
        for l in gp.salist:
            if len(l):
                # deprecated command abbreviations 
                # print l[0]
                available_commands.append(l[1])
        # -> matlab wrapped commands
        for l in gm.functions.keys():
            available_commands.append(l)

        # print
        available_commands.sort()
        for c in available_commands:
            print("  " + c)

    # --- print list of processing options and flags
    elif com in ['o']:
        print "================================================================="
        print ""
        print " QuNex python utilities for processing and analysis"
        print "\nuse: qunex <command> [option=value] [option=value] ..."
        print "\nList of processing options"
        for line in gp.arglist:
            if len(line) == 4:
                print "  --%-24s %s [%s]" % (line[0], line[3], line[1])
            elif len(line) > 0:
                print "\n\n" + line[0] + '\n'
            else:
                print
        print "\nList of processing flags"
        for line in gp.flaglist:
            if len(line) == 4:
                print "  --%-24s %s" % (line[0], line[3])
            elif len(line) > 0:
                print "\n\n" + line[0] + '\n'
            else:
                print
        print

    # --- print help for gmri local commands
    elif com in gcom.commands:
        print "\nqunex", gcom.commands[com]['com'].__doc__.strip(), "\n"

    # --- print help for processing actions
    elif com in gp.allactions:
        print "\nqunex", gp.allactions[com].__doc__.strip(), "\n"

    # --- print help for matlab functions
    elif com in gm.functions:
        gm.help(com)

    # --- print general command list
    else:
        print comlist


def main(args=None):
    if args is None:
        args = sys.argv[1:]

    oargs = copy.deepcopy(args)

    if len(args) == 0:
        print help
        sys.exit(0)

    comm = args[0]
    opts = dict()

     # --- check if help arguments are specified and strip all flags (? or -)
    if comm[0] in ['?', '-']:
        comm = comm.strip('-')
        comm = comm.strip('?')
        try:
            printHelp(comm[0:])
        except:
            print "ERROR: '%s' is not a recognized command!\n-----------------------" % (comm[1:])
            print help
            raise
        sys.exit(0)

    try:
        for n in range(1, len(args)):
            if "=" in args[n]:
                k, v = args[n].split("=", 1)
                k = k.strip('-')
                opts[k] = v
            elif comm in gcom.commands:
                k = gcom.commands[comm]['args'][n - 1]
                opts[k] = args[n]
            else:
                k = args[n].strip('-')
                opts[k] = True
        runCommand(comm, opts)


    except ge.CommandNull as e:
        print ge.reportCommandNull(comm, e)
        print
        sys.exit(0)
    except ge.CommandFailed as e:
        print ge.reportCommandFailed(comm, e)
        print
        sys.exit(1)
    except ge.CommandError as e:
        print ge.reportCommandError(comm, e)
        print "\nThe call received was: \n(please note that when run through scheduler, all possible parameters, \neven non relevant ones are passed) \n\nqunex %s " % (" \\\n    ".join(oargs))
        print "\nPlease run `qunex ?%s` to get help for the failed command.\n" % (comm)
        sys.exit(1)
    except ValueError as e:
        print "\n--------------------==== QuNex failed! ====--------------------\nERROR: Execution of qunex command %s failed!" % (comm)
        print e
        print "\nThe call received was: \n(please note that when run through scheduler, all possible parameters, \neven non relevant ones are passed) \n\nqunex %s " % (" \\\n    ".join(oargs))
        raise
    except SystemExit as e:
        sys.exit(e)
    except:
        print "\n--------------------==== QuNex failed! ====--------------------\n\nERROR: Execution of command `%s` failed!" % (comm)
        print "       Please check documentation for the command (`qunex ?%s`)!" % (comm)
        print "\nThe call received was: \n(please note that when run through scheduler, all possible parameters, \neven non relevant ones are passed) \n\nqunex %s " % (" \\\n    ".join(oargs))
        print "\n--------------------------------------------------------------\nHere's the error as caught by python:\n"
        raise


if __name__ == "__main__":
    main()
