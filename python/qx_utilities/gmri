#!/usr/bin/env python2.7
# encoding: utf-8

import os.path
import sys
import copy
import datetime
from general import scheduler as gs
from general import utilities as gu
from general import process as gp
from general import matlab as gm
from general import core as gc
from general import exceptions as ge
from general import commands as gcom
from general import commands_support as gcs

help = '''
  QuNex python utilities (python qx_utilities) for Preprocessing and Analyses   
--------------------------------------------------------------------------------

 DESCRIPTION: QuNex Suite workflows contain python-based general neuroimaging 
 utilities. QuNex python utilities can be invoked via the "qunex <command>" call.

                        General QuNex Usage Syntax
================================================================================

 qunex <command> \
   --parameterA=<value> \
   [--parameterB=<value>]
  =>  --   Dashes or "flags" denote parameters.
  =>  []   Square brackets denote optional parameters. 
             Note: What is shown inside [] denotes default values of optional parameters. 
  =>  <>   Angle brackets denote user-specified values for a given parameter.
  => commands, parameters and values are shown in small or "camel" case.

'''

#
# Took out these two functions until fully integrated to avoid documentation confusion w/ bash qx_utilities
# Also these should not be referenced as 'hcp' functions as they are not
#
# hcp_dtifit    Run FSL DTI fit.
# hcp_bedpostx  Run FSL Bedpostx GPU.

comlist = r'''
 QuNex python utilities (python qx_utilities) for Preprocessing and Analyses 
=============================================================================

 Scheduling command
===================

schedule [command=<command string>] [script=<path to script>] \
         settings=<settings string> \
         [replace=<"key:value|key:value" string>] \
         [workdir=<path to working directory>] \
         [environment=<path to environment setup script>] \
         [output=<string specifying how to process output>]

 Processing commands
=====================
In contrast to commands listed above, processing commands can be submitted to
run on a computer cluster using either a PBS or LSF scheduling. The commands
operate on a list of sessions specified in a `batch.txt` file that provides
information about each session and his or her images and other information.
Options for the processing command can be specified either in the `batch.txt`
file or on the command line, the latter having priority if a parameter is
specified at both levels. No options need to be set for any of the commands
listed below. The key parameters with their default values are:

    --sessions=batch.txt    the path to the batch.txt file
    --sessionsfolder=.      the path to the study sessions folder
    --overwrite=no          whether to overwrite existing results
    --parsessions=1         how many sessions to run in parallel
    --nprocess=0            how many sessions to process (0=all)
    --log=remove            whether to remove logs of commands that have
                            ran and finished successfully
    --run=run               whether to run (run) the listed command or
                            test (test) if all the data is ready for the
                            specific command to run successfully

Please note that each of the commands can be run by specifying its short 
(listed first) or full (listed second) name followed by specfication of
processing options. 

 WUSTL NIL pipeline commands
=============================
  run_nil         [folder=.] [overwrite=no] [sourcefile=session.txt]
  run_nil_folder  [folder=.] [pattern=OP*] [overwrite=no] [sourcefile=session.txt]

 General image file commands
=============================
 slice_image     sourcefile=<source image> targetfile=<target image> [frames=1]

 NIfTI file conversion commands
================================
  fz2zf           inf=<input_image> [outf=<output_image>]
  reorder         inf=<input_image> [outf=<output_image>]
  reslice         inf=<input_image> slices=<slices_per_volume> [outf=<output_image>]
  printniftihdr   <image_filename>
  modniftihdr     <image_filename> <modification string>
  nifti24dfp      inf=<input_filename> [outf=<output_filename>]

 Workbench surface mapping commands
===================================
  map2pals    volume=<volume file> metric=<metric file> [atlas=711-2C] [method=interpolated] [mapping=afm]
  map2hcp     volume=<volume file> [method=trilinear]
  mask_map    image=<image file> masks=<list of masks to use> [output=<output image name>] [minv=<list of thresholds>] [maxv=<list of thresholds>] [join=<OR or AND>]
  join_maps   images=<image file list> output=<output file name> [names=<volume names list>] [originals=<remove or keep>]

 General purpose commands
==========================
  run_shell_script    Runs the specified script.

 Legacy commands
=================
  run_basic_segmentation  Run basic structural image segmentation using BET and FAST.
  get_fs_data             Copy existing FreeSurfer data to sessions' images folder.
  run_subcortical_fs      Run subcortical freesurfer segmentation.
  run_full_fs             Run full freesurfer segmentation

 MATLAB commands supported via python qx_utilities
===================================================
A number of MATLAB commands provided as part of QuNex can be  invoked via the
python qx_utilities engine. A list of commands currently supported is 
provided below. For more information run `qunex <command>`. 

Note that parameters can be specified in any order. Parameters that are not provided 
will be passed as empty and will be processed with default values. Take care to embed 
vectors in square brackets (e.g. "[1 8 6 12]") and cell arrays in curly braces 
(e.g. "{'DLPFC', 'ACC', 'FEF'}"). In addition, 'saveOutput' parameter can be specified 
to redirect Matlab output to a file: (e.g. "both:command.log" or "stdout:ok.log|stderr:error.log").

Example call of a QuNex MATLAB command:

 qunex general_find_peaks \\
  --fin='map_zstat.dscalar.nii' \\
  --fout='map_peaks.dscalar.nii' \\
  --mins="[50 50]" --maxs="[300 350]" \\
  --val=n t=3.5 \\
  --projection=midthickness


 ==> List of MATLAB commands supported via python qx_utilities:
'''

for mcom in gm.functionList:
    comlist += "\n " + mcom

core_qunex_commands = r'''
=========================================
 Listing of all QuNex supported commands
=========================================

  anat_parcellate                           Parcellate T1w and T2w derived measures (e.g. myelin or thickness)
  bold_compute_fc                           Computes seed or GBC BOLD functional connectivity
  bold_parcellate                           Parcellate BOLD data and generate pconn files
  check_fidl                                TODO DESCRIPTION
  compute_bold_stats                        Compute BOLD movement and signal statistics.
  create_batch                              TODO DESCRIPTION
  create_bold_brain_masks                   Create brain masks for BOLD runs.
  create_conc                               TODO DESCRIPTION
  create_list                               TODO DESCRIPTION
  create_session_info                       TODO DESCRIPTION
  create_stats_report                       Create BOLD movement statistic reports and plots.
  create_study                              TODO DESCRIPTION
  create_ws_palm_design                     TODO DESCRIPTION
  data_sync                                 Sync/backup data across hpc cluster(s)
  dicom2nii                                 TODO DESCRIPTION
  dicom2niix                                TODO DESCRIPTION
  dwi_legacy                                Diffusion image processing for data with or without standard fieldmaps
  dwi_eddy_qc                               Run quality control on diffusion datasets following eddy outputs
  dwi_fsl_dtifit                            Run FSL's dtifit tool (cluster usable)
  dwi_fsl_bedpostx_gpu                      Run FSL GPU-enabled bedpostx
  dwi_pre_tractography                      Generates space for dense whole-brain connectomes
  dwi_probtrackx_dense_gpu                  Run FSL's GPU-enabled probtrackx for dense whole-brain connectomes
  dwi_seed_tractography_dense               Reduce dense tractography data using a seed structure
  dwi_parcellate                            Parcellate dense tractography data
  extract_nuisance_signal                   Extract nuisance signal from BOLD images.
  extract_roi                               Extract data from pre-specified ROIs in CIFTI or NIFTI
  fc_compute_ab_corr                        TODO DESCRIPTION
  fc_compute_ab_corr_kca                    TODO DESCRIPTION
  fc_compute_gbc3                           TODO DESCRIPTION
  fc_compute_gbcd                           TODO DESCRIPTION
  fc_compute_roifc                          TODO DESCRIPTION
  fc_compute_roifc_group                    TODO DESCRIPTION
  fc_compute_seedmaps_group                 TODO DESCRIPTION
  fc_compute_seedmaps_group                 TODO DESCRIPTION
  fc_compute_seedmaps_multiple              TODO DESCRIPTION
  fc_extract_roi_timeseries_masked          TODO DESCRIPTION
  fc_extract_trial_timeseries_masked        TODO DESCRIPTION
  fc_mri_segment                            TODO DESCRIPTION
  fc_preprocess                             TODO DESCRIPTION
  fc_preprocess_conc                        TODO DESCRIPTION
  fsl_f99                                   Run FSL F99 command.
  fsl_xtract                                Run FSL XTRACT command.
  general_compute_bold_list_stats           TODO DESCRIPTION
  general_compute_bold_stats                TODO DESCRIPTION
  general_compute_group_bold_stats          TODO DESCRIPTION
  general_extract_glm_volumes               TODO DESCRIPTION
  general_extract_roi_glm_values            TODO DESCRIPTION
  general_extract_roi_values                TODO DESCRIPTION
  general_find_peaks                        TODO DESCRIPTION
  general_image_conjunction                 TODO DESCRIPTION
  general_image_overlap                     TODO DESCRIPTION
  general_parcellated2dense                 TODO DESCRIPTION
  general_plot_bold_timeseries              TODO DESCRIPTION
  general_plot_bold_timeseries_list         TODO DESCRIPTION
  general_qa_concfile                       TODO DESCRIPTION
  hcp_dedrift_and_resample                  Run HCP MSMAll pipeline.
  hcp_diffusion                             Run HCP DWI pipeline.
  hcp_fmri_surface                          Run HCP fMRI Surface pipeline.
  hcp_fmri_volume                           Run HCP fMRI Volume pipeline.
  hcp_freesurfer                            Run HCP FreeSurfer pipeline.
  hcp_icafix                                Run HCP ICAFix pipeline.
  hcp_msmall                                Run HCP MSMAll pipeline.
  hcp_post_fix                              Run HCP PostFix pipeline.
  hcp_post_freesurfer                       Run HCP Post FreeSurfer pipeline.
  hcp_pre_freesurfer                        Run HCP PreFreeSurfer pipeline.
  hcp_reapply_fix                           Run HCP ReApplyFix pipeline.
  import_bids                               TODO DESCRIPTION
  import_dicom                              TODO DESCRIPTION
  import_hcp                                TODO DESCRIPTION
  join_fidl                                 TODO DESCRIPTION
  join_fidl_folder                          TODO DESCRIPTION
  list_dicom                                TODO DESCRIPTION
  map_bids2nii                              TODO DESCRIPTION
  map_hcp_data                              Map HCP preprocessed data to sessions' image folder.
  map_hcp_files                             TODO DESCRIPTION
  map_hcpls2nii                             TODO DESCRIPTION
  organize_dicom                            TODO DESCRIPTION
  preprocess_bold                           Preprocess single BOLD images.
  preprocess_conc                           Preprocess conc bundles of BOLD images.
  run_palm                                  TODO DESCRIPTION
  run_qc                                    Run visual qc for a given modality: raw nifti,t1w,tw2,myelin,bold,dwi
  run_turnkey                               Turnkey execution of QuNex workflow compatible with XNAT Docker engine
  setup_hcp                                 TODO DESCRIPTION
  sort_dicom                                TODO DESCRIPTION
  split_dicom                               TODO DESCRIPTION
  split_fidl                                TODO DESCRIPTION
  stats_compute_behavioral_correlations     TODO DESCRIPTION
  stats_p2z                                 TODO DESCRIPTION
  stats_ttest_dependent                     TODO DESCRIPTION
  stats_ttest_independent                   TODO DESCRIPTION
  stats_test_zero                           TODO DESCRIPTION
'''

def runCommand(command, args):

    folders = gc.deduceFolders(args)

    if folders['basefolder']:
        gu.checkStudy(folders['basefolder'])

    # --- check if command is deprecated
    command = gcs.check_deprecated_commands(command)

    # -- remap deprecated arguments
    args = gcs.check_deprecated_parameters(args, command)

    # --- sort commands by type
    if command in gcom.commands:
        pass
    elif command in gp.allactions:
        gp.run(command, args)
        return
    elif command in gm.functions:
        if 'scheduler' in args:
            gs.runThroughScheduler(command, sessions=None, args=args, parsessions=1, logfolder=folders['logfolder'])
        else:
            gm.run(command, args)
        return
    else:
        print "ERROR: Command %s not recognized. Please run gmri -l to see list of valid commands." % (command)
        sys.exit(1)

    # --- process commands
    # -- sort arguments
    bargs = {}
    eargs = {}
    for k, v in args.items():
        if k in gcom.commands[command]['args']:
            bargs[k] = v
        else:
            eargs[k] = v

    # -- check extra arguments, except for run_list
    if eargs and command != "run_list":
        bad = []
        for k, v in eargs.items():
            if k not in gcs.extra_parameters:
                bad.append(k)
                print "ERROR: Extra argument %s is not valid! Please check your command!" % (k)
        if bad:
            raise ge.CommandError("gmri", "Invalid arguments", "The extra argument(s) provided is/are not valid! [%s]" % (", ".join(bad)))

    # -- process extra arguments
    sessions = None
    if 'sessions' in eargs:
        if command != "run_list" and not any([e in gcom.commands[command]['args'] for e in ['sourcefolder', 'folder']]):
            raise ge.CommandError("gmri", "Incompatible command", "Command %s can not be run on multiple sessions!" % (command))
        if folders['sessionsfolder'] is None:
            folders['sessionsfolder'] = "."
        sessions, _ = gc.getSessionList(eargs['sessions'], filter=eargs.get('filter'), sessionids=eargs.get('sessionids'), sessionsfolder=folders['sessionsfolder'], verbose=False)

    logname = eargs.get('logname')

    calls = []

    # -- run_list specifics
    if command == "run_list":
        if sessions and 'sperlist' in eargs:

            if 'scheduler' in eargs:
                # -- define number of sessions to run in each run_list
                parsessions = int(eargs['sperlist'])
                args['parsessions'] = eargs['sperlist']
                if 'ignore' in args:
                    args['ignore'] += 'scheduler'
                else:
                    args['ignore'] = 'scheduler'
                del args['sperlist']

                gs.runThroughScheduler(command, sessions=sessions, args=args, parsessions=parsessions, logfolder=folders['logfolder'], logname=logname)
            
            else:
                # -- define number of sessions to run in each run_list
                sperlist = args['sperlist']
                del args['sperlist']

                # -- define number of run_list to run in parallel
                parsessions = eargs.get('runinpar', 1)
                args['parsessions'] = parsessions
                if 'runinpar' in args:
                    del args['runinpar']

                c = 0
                while sessions:
                    c += 1
                    largs = args.copy()

                    # -- set up a list of sessions to run in each run_list

                    slist = [sessions.pop(0)['id'] for e in range(sperlist) if sessions]
                    largs['sessionids'] = "|".join(slist)

                    calls.append({'name': 'run_list_%d' % (c), 'function': gcom.commands[command]['com'], 'args': largs, 'logfile': None})

        else:
            # -- if using a scheduler schedule the whole run_list commmand
            if 'scheduler' in eargs:
                if 'ignore' in args:
                    args['ignore'] += 'scheduler'
                else:
                    args['ignore'] = 'scheduler'

                runListFolder = folders['logfolder']

                # create folder if it does not exist
                if not os.path.isdir(runListFolder):
                    os.makedirs(runListFolder)

                runListFolder = os.path.join(runListFolder, "batchlogs")

                # create folder if it does not exist
                if not os.path.isdir(runListFolder):
                    os.makedirs(runListFolder)

                logstamp = datetime.datetime.now().strftime("%Y-%m-%d_%H.%M.%s")
                logname = os.path.join(runListFolder, "Log-%s-%s.log") % ("runlist", logstamp)

                gs.runThroughScheduler(command, args=args, logfolder=runListFolder, logname=logname)

            else:
                bargs['eargs'] = eargs
                gcom.commands[command]['com'](**bargs)
                print "\n===> Successful completion of task"

    # -- all other commands    
    else:
        parsessions = int(eargs.get('parsessions', '1'))

        # -- are we using a scheduler
        if 'scheduler' in eargs:
            gs.runThroughScheduler(command, sessions=sessions, args=args, parsessions=parsessions, logfolder=folders['logfolder'], logname=logname)

        # -- a basic call
        elif sessions is None:
            # logfolder
            if not folders['logfolder']:
                folders['logfolder'] = "."

            # createstudy exception
            if command == "create_study" and "studyfolder" in args:
                folders['logfolder'] = args["studyfolder"] + "/processing/logs"
            elif command == "create_study":
                folders['logfolder'] = "./processing/logs"

            # if case is provided
            sufix = ""
            if "sessions" in args:
                sufix = "_" + args["sessions"]

            logfile = os.path.join(folders['logfolder'], 'comlogs', "%s%s.log" % (command, sufix))

            # run without log for exceptions
            # remove logs for exceptions
            if command in gcs.logskip_commands:
                gcom.commands[command]['com'](**args)
            # run with log
            else:
                _, result, _, _ = gc.runWithLog(gcom.commands[command]['com'], args=args, logfile=logfile)

        # -- sessions loop
        else:
            for session in sessions:
                targs   = dict(bargs)
                name    = command + ": " + session['id']
                sessionsfolder = os.path.join(folders['sessionsfolder'], session['id'])
                if folders['logfolder']:
                    logfile = os.path.join(folders['logfolder'], 'comlogs', "%s_%s.log" % (command, session['id']))
                for targ in ['sourcefolder', 'folder']:
                    if targ in gcom.commands[command]['args']:
                        targs[targ] = sessionsfolder

                calls.append({'name': name, 'function': gcom.commands[command]['com'], 'args': targs, 'logfile': logfile})

    # -- Have we set up calls to run in parallel?
    if calls:
        callInfo = "Running %s" % (command)
        callInfo += "\n" + "".join(['=' for e in range(len(callInfo))])
        print callInfo
        
        print "\n===> Running %s through %d sessions in parallel" % (command, parsessions)

        results = gc.runInParallel(calls, cores=parsessions, prepend="     ... ")

        ok = True
        print "\n===> Final report for command", command
        results.sort(key=lambda x: x[0])
        for name, result, targetLog, prepend in results:
            if result:                
                ok = False
            else:
                result = 'completed'
            print "%s %s %s [log: %s]" % (prepend, name, result, targetLog)
        if ok:
            print "\n===> Successful completion of task"


def printHelp(com):

    # --- print list of available commands, required for qunex.sh checks
    if com == 'available':
        available_commands = []
        # -> gmri commands
        for c, _ in gcom.commands.iteritems():
            available_commands.append(c)
        # -> complex processing commands
        for l in gp.calist:
            if len(l):
                # deprecated command abbreviations 
                available_commands.append(l[1])
        # -> longitudinal processing commands
        for l in gp.lalist:
            if len(l):
                # deprecated command abbreviations 
                available_commands.append(l[1])
        # -> simple processing commands
        for l in gp.salist:
            if len(l):
                # deprecated command abbreviations 
                available_commands.append(l[1])
        # -> matlab wrapped commands
        for l in gm.functions.keys():
            available_commands.append(l)

        # print the commands
        available_commands.sort()
        print " ".join(available_commands)

    # --- print list of processing options and flags
    # elif com in ['o']:
    #     print "================================================================="
    #     print ""
    #     print " QuNex python utilities for processing and analysis"
    #     print "\nuse: qunex <command> [option=value] [option=value] ..."
    #     print "\nList of processing options"
    #     for line in gp.arglist:
    #         if len(line) == 4:
    #             print "  --%-24s %s [%s]" % (line[0], line[3], line[1])
    #         elif len(line) > 0:
    #             print "\n\n" + line[0] + '\n'
    #         else:
    #             print
    #     print "\nList of processing flags"
    #     for line in gp.flaglist:
    #         if len(line) == 4:
    #             print "  --%-24s %s" % (line[0], line[3])
    #         elif len(line) > 0:
    #             print "\n\n" + line[0] + '\n'
    #         else:
    #             print
    #     print

    # --- print core commands
    elif com == "core":
        print core_qunex_commands

    # --- print error
    else:
        print "\nERROR: %s --> Requested command is not supported. Refer to general QuNex usage.\n" % com


def main(args=None):
    if args is None:
        args = sys.argv[1:]

    oargs = copy.deepcopy(args)

    if len(args) == 0:
        print help
        sys.exit(0)

    comm = args[0]
    opts = dict()

     # --- check if help arguments are specified and strip all flags (? or -)
    if comm[0] in ['?', '-']:
        comm = comm.strip('-')
        comm = comm.strip('?')
        try:
            command = comm[0:]
            command = gcs.check_deprecated_commands(command)
            printHelp(command)
        except:
            print "ERROR: '%s' is not a recognized command!\n-----------------------" % (comm[1:])
            print help
            raise
        sys.exit(0)

    try:
        for n in range(1, len(args)):
            if "=" in args[n]:
                k, v = args[n].split("=", 1)
                k = k.strip('-')
                opts[k] = v
            elif comm in gcom.commands:
                k = gcom.commands[comm]['args'][n - 1]
                opts[k] = args[n]
            else:
                k = args[n].strip('-')
                opts[k] = True
        runCommand(comm, opts)


    except ge.CommandNull as e:
        print ge.reportCommandNull(comm, e)
        print
        sys.exit(0)
    except ge.CommandFailed as e:
        print ge.reportCommandFailed(comm, e)
        print
        sys.exit(1)
    except ge.CommandError as e:
        print ge.reportCommandError(comm, e)
        print "\nThe call received was: \n(please note that when run through scheduler, all possible parameters, \neven non relevant ones are passed) \n\nqunex %s " % (" \\\n    ".join(oargs))
        print "\nPlease run `qunex ?%s` to get help for the failed command.\n" % (comm)
        sys.exit(1)
    except ValueError as e:
        print "\n--------------------==== QuNex failed! ====--------------------\nERROR: Execution of qunex command %s failed!" % (comm)
        print e
        print "\nThe call received was: \n(please note that when run through scheduler, all possible parameters, \neven non relevant ones are passed) \n\nqunex %s " % (" \\\n    ".join(oargs))
        raise
    except SystemExit as e:
        sys.exit(e)
    except:
        print "\n--------------------==== QuNex failed! ====--------------------\n\nERROR: Execution of command `%s` failed!" % (comm)
        print "       Please check documentation for the command (`qunex ?%s`)!" % (comm)
        print "\nThe call received was: \n(please note that when run through scheduler, all possible parameters, \neven non relevant ones are passed) \n\nqunex %s " % (" \\\n    ".join(oargs))
        print "\n--------------------------------------------------------------\nHere's the error as caught by python:\n"
        raise


if __name__ == "__main__":
    main()
